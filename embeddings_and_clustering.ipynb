{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>bloom</th>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>llama_13b</th>\n",
       "      <th>gpt4all</th>\n",
       "      <th>llama_7b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1642025557511532545</td>\n",
       "      <td>the white paws, the cute collar, the tongue, t...</td>\n",
       "      <td>Yes, the above tweet is a potential lead. The...</td>\n",
       "      <td>Yes, this tweet is a potential lead because it...</td>\n",
       "      <td>Yes, the tweet is a potential lead because it ...</td>\n",
       "      <td>1. What is your analysis of the tweet in terms...</td>\n",
       "      <td>\\n\\nAnswer:\\n\\nYes, the above tweet is a poten...</td>\n",
       "      <td>Yes. The reason is that it has all the charac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          full_text  \\\n",
       "0  1642025557511532545  the white paws, the cute collar, the tongue, t...   \n",
       "\n",
       "                                               bloom  \\\n",
       "0   Yes, the above tweet is a potential lead. The...   \n",
       "\n",
       "                                           alpaca_3b  \\\n",
       "0  Yes, this tweet is a potential lead because it...   \n",
       "\n",
       "                                         alpaca_770m  \\\n",
       "0  Yes, the tweet is a potential lead because it ...   \n",
       "\n",
       "                                           llama_13b  \\\n",
       "0  1. What is your analysis of the tweet in terms...   \n",
       "\n",
       "                                             gpt4all  \\\n",
       "0  \\n\\nAnswer:\\n\\nYes, the above tweet is a poten...   \n",
       "\n",
       "                                            llama_7b  \n",
       "0   Yes. The reason is that it has all the charac...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = pd.read_parquet('outputs/0S_100T_all_models_202345.parquet')\n",
    "outputs.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models: ['bloom', 'alpaca_3b', 'alpaca_770m', 'llama_13b', 'gpt4all', 'llama_7b']\n"
     ]
    }
   ],
   "source": [
    "model_cols = outputs.columns[2:].to_list()\n",
    "print(f'Models: {model_cols}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence embeddings\n",
    "\n",
    "Using sentence embeddings out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:40:59,127 - INFO     | config     | Loading environment variables\n"
     ]
    }
   ],
   "source": [
    "from models.embeddings import SentenceEmbeddings\n",
    "\n",
    "sentence_embeddings_df = outputs.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mpnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:41:00,703 - INFO     | models.embeddings | Initializing MPNET for Sentence Embeddings\n",
      "2023-04-18 16:41:00,704 - INFO     | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-mpnet-base-v2\n",
      "2023-04-18 16:41:01,468 - INFO     | sentence_transformers.SentenceTransformer | Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "mpnet = SentenceEmbeddings(name='mpnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:41:01,486 - INFO     | __main__   | Parsing model: bloom\n",
      "2023-04-18 16:41:01,486 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3511033a6afb4ebaa19bb416332293a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:41:02,396 - INFO     | __main__   | Parsing model: alpaca_3b\n",
      "2023-04-18 16:41:02,396 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6727686b67a549149e8b91b0d39a3687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:41:04,678 - INFO     | __main__   | Parsing model: alpaca_770m\n",
      "2023-04-18 16:41:04,679 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa6d11f57564a97a2d4880df32a38bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:41:06,852 - INFO     | __main__   | Parsing model: llama_13b\n",
      "2023-04-18 16:41:06,852 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374193af0ef44c799d6c870d8d92a1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:41:15,511 - INFO     | __main__   | Parsing model: gpt4all\n",
      "2023-04-18 16:41:15,511 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0915385bb093446495fb8c360a910772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:41:19,386 - INFO     | __main__   | Parsing model: llama_7b\n",
      "2023-04-18 16:41:19,386 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1d990ab64d14e67bbfb1bfd41719092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpnet_dict = {}\n",
    "for col in model_cols:\n",
    "    logger.info(f'Parsing model: {col}')\n",
    "    mpnet_dict[col] = mpnet.generate_embeddings(input_texts=sentence_embeddings_df[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distil-roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:41:27,571 - INFO     | models.embeddings | Initializing DISTIL-ROBERTA for Sentence Embeddings\n",
      "2023-04-18 16:41:27,571 - INFO     | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-distilroberta-v1\n",
      "2023-04-18 16:41:28,236 - INFO     | sentence_transformers.SentenceTransformer | Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "distilrberta = SentenceEmbeddings(name='distil-roberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:41:28,252 - INFO     | __main__   | Parsing model: bloom\n",
      "2023-04-18 16:41:28,253 - INFO     | models.embeddings | DISTIL-ROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad897d19ab614a49ab150ab2cd7dee6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:41:28,657 - INFO     | __main__   | Parsing model: alpaca_3b\n",
      "2023-04-18 16:41:28,657 - INFO     | models.embeddings | DISTIL-ROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0789cc5fbe37480096b23abe3a57ed67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:41:29,790 - INFO     | __main__   | Parsing model: alpaca_770m\n",
      "2023-04-18 16:41:29,790 - INFO     | models.embeddings | DISTIL-ROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "263a5b9e49bb4b2ca5b7f723fa7822aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:41:30,789 - INFO     | __main__   | Parsing model: llama_13b\n",
      "2023-04-18 16:41:30,790 - INFO     | models.embeddings | DISTIL-ROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1292d9b0514ac791f4085b5f4e0e8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:41:35,263 - INFO     | __main__   | Parsing model: gpt4all\n",
      "2023-04-18 16:41:35,263 - INFO     | models.embeddings | DISTIL-ROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cacb5e158eec4f62b28868b12444f998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:41:37,146 - INFO     | __main__   | Parsing model: llama_7b\n",
      "2023-04-18 16:41:37,146 - INFO     | models.embeddings | DISTIL-ROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fde69d2f1ef144f88ee5e4ec7b4a0f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distil_dict = {}\n",
    "for col in model_cols:\n",
    "    logger.info(f'Parsing model: {col}')\n",
    "    distil_dict[col] = distilrberta.generate_embeddings(input_texts=sentence_embeddings_df[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "\n",
    "Creating tokens, word embeddings and averaging them to create one vector per output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lorenzo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/lorenzo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from models.embeddings import WordEmbeddings\n",
    "from helpers.embeddings_helpers import clean_and_tokenize_text\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting text columns to string columns\n",
    "word_embeddings_df = outputs.copy()\n",
    "text_cols = outputs.columns[1:]\n",
    "for col in text_cols:\n",
    "    word_embeddings_df[col] = word_embeddings_df[col].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>bloom</th>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>llama_13b</th>\n",
       "      <th>gpt4all</th>\n",
       "      <th>llama_7b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1642025557511532545</td>\n",
       "      <td>the white paws, the cute collar, the tongue, t...</td>\n",
       "      <td>[yes, tweet, potential, lead, tweet, potential...</td>\n",
       "      <td>[yes, tweet, potential, lead, describing, pote...</td>\n",
       "      <td>[yes, tweet, potential, lead, contains, lot, p...</td>\n",
       "      <td>[analysis, tweet, terms, marketing, customer, ...</td>\n",
       "      <td>[answer, yes, tweet, potential, lead, tweet, c...</td>\n",
       "      <td>[yes, reason, characteristics, potential, lead...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          full_text  \\\n",
       "0  1642025557511532545  the white paws, the cute collar, the tongue, t...   \n",
       "\n",
       "                                               bloom  \\\n",
       "0  [yes, tweet, potential, lead, tweet, potential...   \n",
       "\n",
       "                                           alpaca_3b  \\\n",
       "0  [yes, tweet, potential, lead, describing, pote...   \n",
       "\n",
       "                                         alpaca_770m  \\\n",
       "0  [yes, tweet, potential, lead, contains, lot, p...   \n",
       "\n",
       "                                           llama_13b  \\\n",
       "0  [analysis, tweet, terms, marketing, customer, ...   \n",
       "\n",
       "                                             gpt4all  \\\n",
       "0  [answer, yes, tweet, potential, lead, tweet, c...   \n",
       "\n",
       "                                            llama_7b  \n",
       "0  [yes, reason, characteristics, potential, lead...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: id                                           1642025557511532545\n",
      "full_text      the white paws, the cute collar, the tongue, t...\n",
      "bloom          [yes, tweet, potential, lead, tweet, potential...\n",
      "alpaca_3b      [yes, tweet, potential, lead, describing, pote...\n",
      "alpaca_770m    [yes, tweet, potential, lead, contains, lot, p...\n",
      "llama_13b      [analysis, tweet, terms, marketing, customer, ...\n",
      "gpt4all        [answer, yes, tweet, potential, lead, tweet, c...\n",
      "llama_7b       [yes, reason, characteristics, potential, lead...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# creating word level tokens for each model output\n",
    "for col in model_cols:\n",
    "    word_embeddings_df[col] = word_embeddings_df[col].map(lambda x: clean_and_tokenize_text(x, tokenizer=word_tokenize, stopwords=STOPWORDS))\n",
    "display(word_embeddings_df.head(1))\n",
    "print(f'Tokens: {word_embeddings_df.iloc[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:41:41,587 - INFO     | models.embeddings | Initializing GLOVE-TWITTER for Word Embeddings\n",
      "2023-04-18 16:41:41,675 - INFO     | gensim.models.keyedvectors | loading projection weights from /Users/lorenzo/gensim-data/glove-twitter-200/glove-twitter-200.gz\n",
      "2023-04-18 16:42:52,150 - INFO     | gensim.utils | KeyedVectors lifecycle event {'msg': 'loaded (1193514, 200) matrix of type float32 from /Users/lorenzo/gensim-data/glove-twitter-200/glove-twitter-200.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-04-18T16:42:52.150463', 'gensim': '4.3.1', 'python': '3.9.13 (main, Mar  3 2023, 13:16:29) \\n[Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-13.3.1-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "glove = WordEmbeddings(name='glove-twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:42:52,171 - INFO     | __main__   | Parsing model: bloom\n",
      "2023-04-18 16:42:52,172 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n",
      "2023-04-18 16:42:52,176 - INFO     | __main__   | Parsing model: alpaca_3b\n",
      "2023-04-18 16:42:52,176 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n",
      "2023-04-18 16:42:52,182 - INFO     | __main__   | Parsing model: alpaca_770m\n",
      "2023-04-18 16:42:52,183 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n",
      "2023-04-18 16:42:52,189 - INFO     | __main__   | Parsing model: llama_13b\n",
      "2023-04-18 16:42:52,189 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n",
      "2023-04-18 16:42:52,200 - INFO     | __main__   | Parsing model: gpt4all\n",
      "2023-04-18 16:42:52,201 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n",
      "2023-04-18 16:42:52,208 - INFO     | __main__   | Parsing model: llama_7b\n",
      "2023-04-18 16:42:52,208 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n"
     ]
    }
   ],
   "source": [
    "glove_dict = {}\n",
    "for col in model_cols:\n",
    "    logger.info(f'Parsing model: {col}')\n",
    "    glove_dict[col] = glove.generate_embeddings(word_embeddings_df[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:42:52,240 - INFO     | models.embeddings | Initializing W2V-GOOGLE for Word Embeddings\n",
      "2023-04-18 16:42:52,423 - INFO     | gensim.models.keyedvectors | loading projection weights from /Users/lorenzo/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "2023-04-18 16:43:15,707 - INFO     | gensim.utils | KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /Users/lorenzo/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-04-18T16:43:15.707571', 'gensim': '4.3.1', 'python': '3.9.13 (main, Mar  3 2023, 13:16:29) \\n[Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-13.3.1-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "word2vec = WordEmbeddings(name='w2v-google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:43:15,730 - INFO     | __main__   | Parsing model: bloom\n",
      "2023-04-18 16:43:15,794 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n",
      "2023-04-18 16:43:15,797 - INFO     | __main__   | Parsing model: alpaca_3b\n",
      "2023-04-18 16:43:15,798 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n",
      "2023-04-18 16:43:15,804 - INFO     | __main__   | Parsing model: alpaca_770m\n",
      "2023-04-18 16:43:15,805 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n",
      "2023-04-18 16:43:15,810 - INFO     | __main__   | Parsing model: llama_13b\n",
      "2023-04-18 16:43:15,810 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n",
      "2023-04-18 16:43:15,822 - INFO     | __main__   | Parsing model: gpt4all\n",
      "2023-04-18 16:43:15,822 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n",
      "2023-04-18 16:43:15,832 - INFO     | __main__   | Parsing model: llama_7b\n",
      "2023-04-18 16:43:15,835 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n"
     ]
    }
   ],
   "source": [
    "w2v_dict = {}\n",
    "for col in model_cols:\n",
    "    logger.info(f'Parsing model: {col}')\n",
    "    w2v_dict[col] = word2vec.generate_embeddings(word_embeddings_df[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:43:16,248 - INFO     | models.embeddings | Initializing GLOVE-WIKI for Word Embeddings\n",
      "2023-04-18 16:43:16,370 - INFO     | gensim.models.keyedvectors | loading projection weights from /Users/lorenzo/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz\n",
      "2023-04-18 16:43:50,235 - INFO     | gensim.utils | KeyedVectors lifecycle event {'msg': 'loaded (400000, 300) matrix of type float32 from /Users/lorenzo/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-04-18T16:43:50.235515', 'gensim': '4.3.1', 'python': '3.9.13 (main, Mar  3 2023, 13:16:29) \\n[Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-13.3.1-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "wiki = WordEmbeddings(name='glove-wiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:43:50,252 - INFO     | __main__   | Parsing model: bloom\n",
      "2023-04-18 16:43:50,253 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n",
      "2023-04-18 16:43:50,257 - INFO     | __main__   | Parsing model: alpaca_3b\n",
      "2023-04-18 16:43:50,257 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n",
      "2023-04-18 16:43:50,263 - INFO     | __main__   | Parsing model: alpaca_770m\n",
      "2023-04-18 16:43:50,263 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n",
      "2023-04-18 16:43:50,269 - INFO     | __main__   | Parsing model: llama_13b\n",
      "2023-04-18 16:43:50,269 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n",
      "2023-04-18 16:43:50,280 - INFO     | __main__   | Parsing model: gpt4all\n",
      "2023-04-18 16:43:50,280 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n",
      "2023-04-18 16:43:50,287 - INFO     | __main__   | Parsing model: llama_7b\n",
      "2023-04-18 16:43:50,287 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n"
     ]
    }
   ],
   "source": [
    "wiki_dict = {}\n",
    "for col in model_cols:\n",
    "    logger.info(f'Parsing model: {col}')\n",
    "    wiki_dict[col] = wiki.generate_embeddings(word_embeddings_df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
