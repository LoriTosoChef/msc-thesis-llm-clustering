{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>bloom</th>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>llama_13b</th>\n",
       "      <th>gpt4all</th>\n",
       "      <th>llama_7b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1642025557511532545</td>\n",
       "      <td>the white paws, the cute collar, the tongue, t...</td>\n",
       "      <td>Yes, the above tweet is a potential lead. The...</td>\n",
       "      <td>Yes, this tweet is a potential lead because it...</td>\n",
       "      <td>Yes, the tweet is a potential lead because it ...</td>\n",
       "      <td>1. What is your analysis of the tweet in terms...</td>\n",
       "      <td>\\n\\nAnswer:\\n\\nYes, the above tweet is a poten...</td>\n",
       "      <td>Yes. The reason is that it has all the charac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          full_text  \\\n",
       "0  1642025557511532545  the white paws, the cute collar, the tongue, t...   \n",
       "\n",
       "                                               bloom  \\\n",
       "0   Yes, the above tweet is a potential lead. The...   \n",
       "\n",
       "                                           alpaca_3b  \\\n",
       "0  Yes, this tweet is a potential lead because it...   \n",
       "\n",
       "                                         alpaca_770m  \\\n",
       "0  Yes, the tweet is a potential lead because it ...   \n",
       "\n",
       "                                           llama_13b  \\\n",
       "0  1. What is your analysis of the tweet in terms...   \n",
       "\n",
       "                                             gpt4all  \\\n",
       "0  \\n\\nAnswer:\\n\\nYes, the above tweet is a poten...   \n",
       "\n",
       "                                            llama_7b  \n",
       "0   Yes. The reason is that it has all the charac...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = pd.read_parquet('outputs/0S_100T_all_models_202345.parquet')\n",
    "outputs.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models: ['bloom', 'alpaca_3b', 'alpaca_770m', 'llama_13b', 'gpt4all', 'llama_7b']\n"
     ]
    }
   ],
   "source": [
    "model_cols = outputs.columns[2:].to_list()\n",
    "print(f'Models: {model_cols}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence embeddings\n",
    "\n",
    "Using sentence embeddings out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:30:31,401 - INFO     | config     | Loading environment variables\n"
     ]
    }
   ],
   "source": [
    "from models.embeddings import SentenceEmbeddings\n",
    "\n",
    "sentence_embeddings_df = outputs.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mpnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:30:48,059 - INFO     | models.embeddings | Initializing MPNET for Sentence Embeddings\n",
      "2023-04-20 17:30:48,060 - INFO     | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-mpnet-base-v2\n",
      "2023-04-20 17:30:48,927 - INFO     | sentence_transformers.SentenceTransformer | Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "mpnet = SentenceEmbeddings(name='mpnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:30:48,946 - INFO     | __main__   | Parsing model: bloom\n",
      "2023-04-20 17:30:48,949 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546b6f4f3c2a4e66b69fcb1d77246430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:30:49,930 - INFO     | __main__   | Parsing model: alpaca_3b\n",
      "2023-04-20 17:30:49,930 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1605222471084f21977808fb48694b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:30:52,294 - INFO     | __main__   | Parsing model: alpaca_770m\n",
      "2023-04-20 17:30:52,295 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ba2b89eafa841d7a30f1f131d741030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:30:54,533 - INFO     | __main__   | Parsing model: llama_13b\n",
      "2023-04-20 17:30:54,534 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a308d2b4aa974dafbb3dd4515f5e3419",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:31:03,362 - INFO     | __main__   | Parsing model: gpt4all\n",
      "2023-04-20 17:31:03,362 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7359299dc3eb46b8bcef33cfdbc6cccb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:31:07,358 - INFO     | __main__   | Parsing model: llama_7b\n",
      "2023-04-20 17:31:07,359 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f6daa5637a4bccb3ff9ae421cc0a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpnet_dict = {}\n",
    "for col in model_cols:\n",
    "    logger.info(f'Parsing model: {col}')\n",
    "    mpnet_dict[col] = mpnet.generate_embeddings(input_texts=sentence_embeddings_df[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distil-roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:31:15,395 - INFO     | models.embeddings | Initializing DISTIL-ROBERTA for Sentence Embeddings\n",
      "2023-04-20 17:31:15,395 - INFO     | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-distilroberta-v1\n",
      "2023-04-20 17:31:16,058 - INFO     | sentence_transformers.SentenceTransformer | Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "distilrberta = SentenceEmbeddings(name='distil-roberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:31:16,078 - INFO     | __main__   | Parsing model: bloom\n",
      "2023-04-20 17:31:16,079 - INFO     | models.embeddings | DISTIL-ROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc1783dde3c46dca259c86e5b41cd3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:31:16,473 - INFO     | __main__   | Parsing model: alpaca_3b\n",
      "2023-04-20 17:31:16,474 - INFO     | models.embeddings | DISTIL-ROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220b08a8604940398e91eafb860756e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:31:17,636 - INFO     | __main__   | Parsing model: alpaca_770m\n",
      "2023-04-20 17:31:17,636 - INFO     | models.embeddings | DISTIL-ROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df80370c205a4c91a4a0f9f855be0c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:31:18,687 - INFO     | __main__   | Parsing model: llama_13b\n",
      "2023-04-20 17:31:18,688 - INFO     | models.embeddings | DISTIL-ROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480d3eb0d7e349728539fa75dc2a0b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:31:23,464 - INFO     | __main__   | Parsing model: gpt4all\n",
      "2023-04-20 17:31:23,465 - INFO     | models.embeddings | DISTIL-ROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1b604bbc374ea28358404d9535054a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:31:25,342 - INFO     | __main__   | Parsing model: llama_7b\n",
      "2023-04-20 17:31:25,342 - INFO     | models.embeddings | DISTIL-ROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94a96c2a4f4c4431944a2cf55f9ede07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distil_dict = {}\n",
    "for col in model_cols:\n",
    "    logger.info(f'Parsing model: {col}')\n",
    "    distil_dict[col] = distilrberta.generate_embeddings(input_texts=sentence_embeddings_df[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "\n",
    "Creating tokens, word embeddings and averaging them to create one vector per output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lorenzo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/lorenzo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from models.embeddings import WordEmbeddings\n",
    "from helpers.embeddings_helpers import clean_and_tokenize_text\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting text columns to string columns\n",
    "word_embeddings_df = outputs.copy()\n",
    "text_cols = outputs.columns[1:]\n",
    "for col in text_cols:\n",
    "    word_embeddings_df[col] = word_embeddings_df[col].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>bloom</th>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>llama_13b</th>\n",
       "      <th>gpt4all</th>\n",
       "      <th>llama_7b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1642025557511532545</td>\n",
       "      <td>the white paws, the cute collar, the tongue, t...</td>\n",
       "      <td>[yes, tweet, potential, lead, tweet, potential...</td>\n",
       "      <td>[yes, tweet, potential, lead, describing, pote...</td>\n",
       "      <td>[yes, tweet, potential, lead, contains, lot, p...</td>\n",
       "      <td>[analysis, tweet, terms, marketing, customer, ...</td>\n",
       "      <td>[answer, yes, tweet, potential, lead, tweet, c...</td>\n",
       "      <td>[yes, reason, characteristics, potential, lead...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          full_text  \\\n",
       "0  1642025557511532545  the white paws, the cute collar, the tongue, t...   \n",
       "\n",
       "                                               bloom  \\\n",
       "0  [yes, tweet, potential, lead, tweet, potential...   \n",
       "\n",
       "                                           alpaca_3b  \\\n",
       "0  [yes, tweet, potential, lead, describing, pote...   \n",
       "\n",
       "                                         alpaca_770m  \\\n",
       "0  [yes, tweet, potential, lead, contains, lot, p...   \n",
       "\n",
       "                                           llama_13b  \\\n",
       "0  [analysis, tweet, terms, marketing, customer, ...   \n",
       "\n",
       "                                             gpt4all  \\\n",
       "0  [answer, yes, tweet, potential, lead, tweet, c...   \n",
       "\n",
       "                                            llama_7b  \n",
       "0  [yes, reason, characteristics, potential, lead...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: id                                           1642025557511532545\n",
      "full_text      the white paws, the cute collar, the tongue, t...\n",
      "bloom          [yes, tweet, potential, lead, tweet, potential...\n",
      "alpaca_3b      [yes, tweet, potential, lead, describing, pote...\n",
      "alpaca_770m    [yes, tweet, potential, lead, contains, lot, p...\n",
      "llama_13b      [analysis, tweet, terms, marketing, customer, ...\n",
      "gpt4all        [answer, yes, tweet, potential, lead, tweet, c...\n",
      "llama_7b       [yes, reason, characteristics, potential, lead...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# creating word level tokens for each model output\n",
    "for col in model_cols:\n",
    "    word_embeddings_df[col] = word_embeddings_df[col].map(lambda x: clean_and_tokenize_text(x, tokenizer=word_tokenize, stopwords=STOPWORDS))\n",
    "display(word_embeddings_df.head(1))\n",
    "print(f'Tokens: {word_embeddings_df.iloc[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:31:29,754 - INFO     | models.embeddings | Initializing GLOVE-TWITTER for Word Embeddings\n",
      "2023-04-20 17:31:30,062 - INFO     | gensim.models.keyedvectors | loading projection weights from /Users/lorenzo/gensim-data/glove-twitter-200/glove-twitter-200.gz\n",
      "2023-04-20 17:32:41,553 - INFO     | gensim.utils | KeyedVectors lifecycle event {'msg': 'loaded (1193514, 200) matrix of type float32 from /Users/lorenzo/gensim-data/glove-twitter-200/glove-twitter-200.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-04-20T17:32:41.553818', 'gensim': '4.3.1', 'python': '3.9.13 (main, Mar  3 2023, 13:16:29) \\n[Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-13.3.1-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "glove = WordEmbeddings(name='glove-twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:32:41,595 - INFO     | __main__   | Parsing model: bloom\n",
      "2023-04-20 17:32:41,595 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n",
      "2023-04-20 17:32:41,599 - INFO     | __main__   | Parsing model: alpaca_3b\n",
      "2023-04-20 17:32:41,599 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n",
      "2023-04-20 17:32:41,605 - INFO     | __main__   | Parsing model: alpaca_770m\n",
      "2023-04-20 17:32:41,605 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n",
      "2023-04-20 17:32:41,611 - INFO     | __main__   | Parsing model: llama_13b\n",
      "2023-04-20 17:32:41,611 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n",
      "2023-04-20 17:32:41,622 - INFO     | __main__   | Parsing model: gpt4all\n",
      "2023-04-20 17:32:41,623 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n",
      "2023-04-20 17:32:41,629 - INFO     | __main__   | Parsing model: llama_7b\n",
      "2023-04-20 17:32:41,630 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n"
     ]
    }
   ],
   "source": [
    "glove_dict = {}\n",
    "for col in model_cols:\n",
    "    logger.info(f'Parsing model: {col}')\n",
    "    glove_dict[col] = glove.generate_embeddings(word_embeddings_df[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:32:41,662 - INFO     | models.embeddings | Initializing W2V-GOOGLE for Word Embeddings\n",
      "2023-04-20 17:32:42,049 - INFO     | gensim.models.keyedvectors | loading projection weights from /Users/lorenzo/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "2023-04-20 17:33:06,486 - INFO     | gensim.utils | KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /Users/lorenzo/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-04-20T17:33:06.486119', 'gensim': '4.3.1', 'python': '3.9.13 (main, Mar  3 2023, 13:16:29) \\n[Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-13.3.1-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "word2vec = WordEmbeddings(name='w2v-google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:33:06,526 - INFO     | __main__   | Parsing model: bloom\n",
      "2023-04-20 17:33:06,708 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n",
      "2023-04-20 17:33:06,711 - INFO     | __main__   | Parsing model: alpaca_3b\n",
      "2023-04-20 17:33:06,712 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n",
      "2023-04-20 17:33:06,718 - INFO     | __main__   | Parsing model: alpaca_770m\n",
      "2023-04-20 17:33:06,719 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n",
      "2023-04-20 17:33:06,725 - INFO     | __main__   | Parsing model: llama_13b\n",
      "2023-04-20 17:33:06,726 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n",
      "2023-04-20 17:33:06,737 - INFO     | __main__   | Parsing model: gpt4all\n",
      "2023-04-20 17:33:06,738 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n",
      "2023-04-20 17:33:06,745 - INFO     | __main__   | Parsing model: llama_7b\n",
      "2023-04-20 17:33:06,745 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n"
     ]
    }
   ],
   "source": [
    "w2v_dict = {}\n",
    "for col in model_cols:\n",
    "    logger.info(f'Parsing model: {col}')\n",
    "    w2v_dict[col] = word2vec.generate_embeddings(word_embeddings_df[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:33:06,787 - INFO     | models.embeddings | Initializing GLOVE-WIKI for Word Embeddings\n",
      "2023-04-20 17:33:06,929 - INFO     | gensim.models.keyedvectors | loading projection weights from /Users/lorenzo/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz\n",
      "2023-04-20 17:33:41,278 - INFO     | gensim.utils | KeyedVectors lifecycle event {'msg': 'loaded (400000, 300) matrix of type float32 from /Users/lorenzo/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-04-20T17:33:41.278205', 'gensim': '4.3.1', 'python': '3.9.13 (main, Mar  3 2023, 13:16:29) \\n[Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-13.3.1-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "wiki = WordEmbeddings(name='glove-wiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 17:33:41,320 - INFO     | __main__   | Parsing model: bloom\n",
      "2023-04-20 17:33:41,321 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n",
      "2023-04-20 17:33:41,324 - INFO     | __main__   | Parsing model: alpaca_3b\n",
      "2023-04-20 17:33:41,325 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n",
      "2023-04-20 17:33:41,330 - INFO     | __main__   | Parsing model: alpaca_770m\n",
      "2023-04-20 17:33:41,331 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n",
      "2023-04-20 17:33:41,336 - INFO     | __main__   | Parsing model: llama_13b\n",
      "2023-04-20 17:33:41,336 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n",
      "2023-04-20 17:33:41,347 - INFO     | __main__   | Parsing model: gpt4all\n",
      "2023-04-20 17:33:41,348 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n",
      "2023-04-20 17:33:41,355 - INFO     | __main__   | Parsing model: llama_7b\n",
      "2023-04-20 17:33:41,356 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n"
     ]
    }
   ],
   "source": [
    "wiki_dict = {}\n",
    "for col in model_cols:\n",
    "    logger.info(f'Parsing model: {col}')\n",
    "    wiki_dict[col] = wiki.generate_embeddings(word_embeddings_df[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_EMBEDDINGS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_EMBEDDINGS:\n",
    "    import pickle\n",
    "\n",
    "    embeddings_data = {\n",
    "        'mpnet': mpnet_dict,\n",
    "        'distil' : distil_dict,\n",
    "        'glove': glove_dict,\n",
    "        'wiki': wiki_dict,\n",
    "        'w2v': w2v_dict,\n",
    "    }\n",
    "\n",
    "    for filename, data in embeddings_data.items():   \n",
    "        with open(f'embeddings/{filename}_embeddings_test.pkl', 'wb') as f:\n",
    "            pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
