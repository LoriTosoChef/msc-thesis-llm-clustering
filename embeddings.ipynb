{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>bloom</th>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>llama_13b</th>\n",
       "      <th>gpt4all</th>\n",
       "      <th>llama_7b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1642025557511532545</td>\n",
       "      <td>the white paws, the cute collar, the tongue, t...</td>\n",
       "      <td>Yes, the above tweet is a potential lead. The...</td>\n",
       "      <td>Yes, this tweet is a potential lead because it...</td>\n",
       "      <td>Yes, the tweet is a potential lead because it ...</td>\n",
       "      <td>1. What is your analysis of the tweet in terms...</td>\n",
       "      <td>\\n\\nAnswer:\\n\\nYes, the above tweet is a poten...</td>\n",
       "      <td>Yes. The reason is that it has all the charac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          full_text  \\\n",
       "0  1642025557511532545  the white paws, the cute collar, the tongue, t...   \n",
       "\n",
       "                                               bloom  \\\n",
       "0   Yes, the above tweet is a potential lead. The...   \n",
       "\n",
       "                                           alpaca_3b  \\\n",
       "0  Yes, this tweet is a potential lead because it...   \n",
       "\n",
       "                                         alpaca_770m  \\\n",
       "0  Yes, the tweet is a potential lead because it ...   \n",
       "\n",
       "                                           llama_13b  \\\n",
       "0  1. What is your analysis of the tweet in terms...   \n",
       "\n",
       "                                             gpt4all  \\\n",
       "0  \\n\\nAnswer:\\n\\nYes, the above tweet is a poten...   \n",
       "\n",
       "                                            llama_7b  \n",
       "0   Yes. The reason is that it has all the charac...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = pd.read_parquet('outputs/0S_100T_all_models_202345.parquet')\n",
    "outputs.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models: ['bloom', 'alpaca_3b', 'alpaca_770m', 'llama_13b', 'gpt4all', 'llama_7b']\n"
     ]
    }
   ],
   "source": [
    "model_cols = outputs.columns[2:].to_list()\n",
    "print(f'Models: {model_cols}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence embeddings\n",
    "\n",
    "Using sentence embeddings out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.embeddings import SentenceEmbeddings\n",
    "\n",
    "sentence_embeddings_df = outputs.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mpnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:20:28,636 - INFO     | models.embeddings | Initializing MPNET for Sentence Embeddings\n",
      "2023-04-18 16:20:28,637 - INFO     | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-mpnet-base-v2\n",
      "2023-04-18 16:20:29,527 - INFO     | sentence_transformers.SentenceTransformer | Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "mpnet = SentenceEmbeddings(name='mpnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:23:32,775 - INFO     | __main__   | Parsing model: bloom\n",
      "2023-04-18 16:23:32,779 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc706e25f544e3b84584da3197ae2c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:23:33,668 - INFO     | __main__   | Parsing model: alpaca_3b\n",
      "2023-04-18 16:23:33,668 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6088edb92a4bcbb96ac9cd2798fac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:23:35,948 - INFO     | __main__   | Parsing model: alpaca_770m\n",
      "2023-04-18 16:23:35,948 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977470d76ef6436e97009acaa0d1534e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:23:38,186 - INFO     | __main__   | Parsing model: llama_13b\n",
      "2023-04-18 16:23:38,186 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5deeeefd17a8495394328c8e0beab408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:23:46,858 - INFO     | __main__   | Parsing model: gpt4all\n",
      "2023-04-18 16:23:46,859 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5532751d28e64c20a5ecff99a5a71da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:23:50,769 - INFO     | __main__   | Parsing model: llama_7b\n",
      "2023-04-18 16:23:50,769 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a631f383f32c4093a806d717a19b22f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mpnet_dict = {}\n",
    "for col in model_cols:\n",
    "    logger.info(f'Parsing model: {col}')\n",
    "    mpnet_dict[col] = mpnet.generate_embeddings(input_texts=sentence_embeddings_df[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### distil-roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:25:28,213 - INFO     | models.embeddings | Initializing DISTILROBERTA for Sentence Embeddings\n",
      "2023-04-18 16:25:28,213 - INFO     | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-distilroberta-v1\n",
      "2023-04-18 16:25:28,880 - INFO     | sentence_transformers.SentenceTransformer | Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "distilrberta = SentenceEmbeddings(name='distil-roberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:25:28,928 - INFO     | __main__   | Parsing model: bloom\n",
      "2023-04-18 16:25:28,928 - INFO     | models.embeddings | DISTILROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b74b30f1d6646d48bc287d8a9e16000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:25:29,329 - INFO     | __main__   | Parsing model: alpaca_3b\n",
      "2023-04-18 16:25:29,329 - INFO     | models.embeddings | DISTILROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3aa84d1f2848de8ebf6757bb31d5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:25:30,460 - INFO     | __main__   | Parsing model: alpaca_770m\n",
      "2023-04-18 16:25:30,461 - INFO     | models.embeddings | DISTILROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa0a3f40ef8d4cb8a9f09fb4a7910309",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:25:31,497 - INFO     | __main__   | Parsing model: llama_13b\n",
      "2023-04-18 16:25:31,498 - INFO     | models.embeddings | DISTILROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad57698dd95f42e890619b4339fd292e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:25:36,035 - INFO     | __main__   | Parsing model: gpt4all\n",
      "2023-04-18 16:25:36,035 - INFO     | models.embeddings | DISTILROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "130d4ac410da44fcb43a57d1c11c7b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:25:37,949 - INFO     | __main__   | Parsing model: llama_7b\n",
      "2023-04-18 16:25:37,950 - INFO     | models.embeddings | DISTILROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8ca5af20ef4c1ab224a4e193d0b8de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distil_dict = {}\n",
    "for col in model_cols:\n",
    "    logger.info(f'Parsing model: {col}')\n",
    "    distil_dict[col] = distilrberta.generate_embeddings(input_texts=sentence_embeddings_df[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "\n",
    "Creating tokens, word embeddings and averaging them to create one vector per output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lorenzo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/lorenzo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from models.embeddings import WordEmbeddings\n",
    "from helpers.embeddings_helpers import clean_and_tokenize_text\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting text columns to string columns\n",
    "word_embeddings_df = outputs.copy()\n",
    "text_cols = outputs.columns[1:]\n",
    "for col in text_cols:\n",
    "    word_embeddings_df[col] = word_embeddings_df[col].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>bloom</th>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>llama_13b</th>\n",
       "      <th>gpt4all</th>\n",
       "      <th>llama_7b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1642025557511532545</td>\n",
       "      <td>the white paws, the cute collar, the tongue, t...</td>\n",
       "      <td>[yes, tweet, potential, lead, tweet, potential...</td>\n",
       "      <td>[yes, tweet, potential, lead, describing, pote...</td>\n",
       "      <td>[yes, tweet, potential, lead, contains, lot, p...</td>\n",
       "      <td>[analysis, tweet, terms, marketing, customer, ...</td>\n",
       "      <td>[answer, yes, tweet, potential, lead, tweet, c...</td>\n",
       "      <td>[yes, reason, characteristics, potential, lead...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          full_text  \\\n",
       "0  1642025557511532545  the white paws, the cute collar, the tongue, t...   \n",
       "\n",
       "                                               bloom  \\\n",
       "0  [yes, tweet, potential, lead, tweet, potential...   \n",
       "\n",
       "                                           alpaca_3b  \\\n",
       "0  [yes, tweet, potential, lead, describing, pote...   \n",
       "\n",
       "                                         alpaca_770m  \\\n",
       "0  [yes, tweet, potential, lead, contains, lot, p...   \n",
       "\n",
       "                                           llama_13b  \\\n",
       "0  [analysis, tweet, terms, marketing, customer, ...   \n",
       "\n",
       "                                             gpt4all  \\\n",
       "0  [answer, yes, tweet, potential, lead, tweet, c...   \n",
       "\n",
       "                                            llama_7b  \n",
       "0  [yes, reason, characteristics, potential, lead...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: id                                           1642025557511532545\n",
      "full_text      the white paws, the cute collar, the tongue, t...\n",
      "bloom          [yes, tweet, potential, lead, tweet, potential...\n",
      "alpaca_3b      [yes, tweet, potential, lead, describing, pote...\n",
      "alpaca_770m    [yes, tweet, potential, lead, contains, lot, p...\n",
      "llama_13b      [analysis, tweet, terms, marketing, customer, ...\n",
      "gpt4all        [answer, yes, tweet, potential, lead, tweet, c...\n",
      "llama_7b       [yes, reason, characteristics, potential, lead...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# creating word level tokens for each model output\n",
    "for col in model_cols:\n",
    "    word_embeddings_df[col] = word_embeddings_df[col].map(lambda x: clean_and_tokenize_text(x, tokenizer=word_tokenize, stopwords=STOPWORDS))\n",
    "display(word_embeddings_df.head(1))\n",
    "print(f'Tokens: {word_embeddings_df.iloc[0]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:32:10,495 - INFO     | models.embeddings | Initializing GLOVE-TWITTER for Word Embeddings\n",
      "2023-04-18 16:32:10,572 - INFO     | gensim.models.keyedvectors | loading projection weights from /Users/lorenzo/gensim-data/glove-twitter-200/glove-twitter-200.gz\n",
      "2023-04-18 16:33:21,290 - INFO     | gensim.utils | KeyedVectors lifecycle event {'msg': 'loaded (1193514, 200) matrix of type float32 from /Users/lorenzo/gensim-data/glove-twitter-200/glove-twitter-200.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-04-18T16:33:21.290020', 'gensim': '4.3.1', 'python': '3.9.13 (main, Mar  3 2023, 13:16:29) \\n[Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-13.3.1-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "glove = WordEmbeddings(name='glove-twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:33:21,329 - INFO     | __main__   | Parsing model: bloom\n",
      "2023-04-18 16:33:21,332 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n",
      "2023-04-18 16:33:21,340 - INFO     | __main__   | Parsing model: alpaca_3b\n",
      "2023-04-18 16:33:21,342 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n",
      "2023-04-18 16:33:21,348 - INFO     | __main__   | Parsing model: alpaca_770m\n",
      "2023-04-18 16:33:21,349 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n",
      "2023-04-18 16:33:21,355 - INFO     | __main__   | Parsing model: llama_13b\n",
      "2023-04-18 16:33:21,357 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n",
      "2023-04-18 16:33:21,371 - INFO     | __main__   | Parsing model: gpt4all\n",
      "2023-04-18 16:33:21,372 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n",
      "2023-04-18 16:33:21,379 - INFO     | __main__   | Parsing model: llama_7b\n",
      "2023-04-18 16:33:21,380 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n"
     ]
    }
   ],
   "source": [
    "glove_dict = {}\n",
    "for col in model_cols:\n",
    "    logger.info(f'Parsing model: {col}')\n",
    "    glove_dict[col] = glove.generate_embeddings(word_embeddings_df[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec Google"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:33:21,877 - INFO     | models.embeddings | Initializing W2V-GOOGLE for Word Embeddings\n",
      "2023-04-18 16:33:21,957 - INFO     | gensim.models.keyedvectors | loading projection weights from /Users/lorenzo/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "2023-04-18 16:33:45,700 - INFO     | gensim.utils | KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /Users/lorenzo/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-04-18T16:33:45.700662', 'gensim': '4.3.1', 'python': '3.9.13 (main, Mar  3 2023, 13:16:29) \\n[Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-13.3.1-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "word2vec = WordEmbeddings(name='w2v-google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:34:06,653 - INFO     | __main__   | Parsing model: bloom\n",
      "2023-04-18 16:34:06,654 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n",
      "2023-04-18 16:34:06,657 - INFO     | __main__   | Parsing model: alpaca_3b\n",
      "2023-04-18 16:34:06,657 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n",
      "2023-04-18 16:34:06,662 - INFO     | __main__   | Parsing model: alpaca_770m\n",
      "2023-04-18 16:34:06,662 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n",
      "2023-04-18 16:34:06,667 - INFO     | __main__   | Parsing model: llama_13b\n",
      "2023-04-18 16:34:06,668 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n",
      "2023-04-18 16:34:06,679 - INFO     | __main__   | Parsing model: gpt4all\n",
      "2023-04-18 16:34:06,679 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n",
      "2023-04-18 16:34:06,690 - INFO     | __main__   | Parsing model: llama_7b\n",
      "2023-04-18 16:34:06,691 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n"
     ]
    }
   ],
   "source": [
    "w2v_dict = {}\n",
    "for col in model_cols:\n",
    "    logger.info(f'Parsing model: {col}')\n",
    "    w2v_dict[col] = word2vec.generate_embeddings(word_embeddings_df[col])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:35:05,089 - INFO     | models.embeddings | Initializing GLOVE-WIKI for Word Embeddings\n",
      "2023-04-18 16:35:05,163 - INFO     | gensim.models.keyedvectors | loading projection weights from /Users/lorenzo/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz\n",
      "2023-04-18 16:35:39,291 - INFO     | gensim.utils | KeyedVectors lifecycle event {'msg': 'loaded (400000, 300) matrix of type float32 from /Users/lorenzo/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-04-18T16:35:39.291208', 'gensim': '4.3.1', 'python': '3.9.13 (main, Mar  3 2023, 13:16:29) \\n[Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-13.3.1-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "wiki = WordEmbeddings(name='glove-wiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:35:39,311 - INFO     | __main__   | Parsing model: bloom\n",
      "2023-04-18 16:35:39,312 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n",
      "2023-04-18 16:35:39,316 - INFO     | __main__   | Parsing model: alpaca_3b\n",
      "2023-04-18 16:35:39,316 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n",
      "2023-04-18 16:35:39,321 - INFO     | __main__   | Parsing model: alpaca_770m\n",
      "2023-04-18 16:35:39,322 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n",
      "2023-04-18 16:35:39,327 - INFO     | __main__   | Parsing model: llama_13b\n",
      "2023-04-18 16:35:39,327 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n",
      "2023-04-18 16:35:39,338 - INFO     | __main__   | Parsing model: gpt4all\n",
      "2023-04-18 16:35:39,338 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n",
      "2023-04-18 16:35:39,346 - INFO     | __main__   | Parsing model: llama_7b\n",
      "2023-04-18 16:35:39,346 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n"
     ]
    }
   ],
   "source": [
    "wiki_dict = {}\n",
    "for col in model_cols:\n",
    "    logger.info(f'Parsing model: {col}')\n",
    "    wiki_dict[col] = wiki.generate_embeddings(word_embeddings_df[col])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
