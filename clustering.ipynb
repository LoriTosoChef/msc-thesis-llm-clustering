{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 08:34:51,020 - INFO     | config     | Loading environment variables\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:45:18,906 - INFO     | __main__   | Loading embeddings/glove_embeddings_test.pkl\n",
      "2023-05-30 17:45:18,909 - INFO     | __main__   | Loading embeddings/mpnet_embeddings_test.pkl\n",
      "2023-05-30 17:45:18,911 - INFO     | __main__   | Loading embeddings/distil_embeddings_test.pkl\n",
      "2023-05-30 17:45:18,914 - INFO     | __main__   | Loading embeddings/wiki_embeddings_test.pkl\n",
      "2023-05-30 17:45:18,916 - INFO     | __main__   | Loading embeddings/w2v_embeddings_test.pkl\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "files = glob.glob('embeddings/*_test.pkl')\n",
    "embeddings_data = {}\n",
    "\n",
    "for file in files:\n",
    "    logger.info(f'Loading {file}')\n",
    "    match_obj = re.search(r'/(?P<output>[^_/]+)_', file)\n",
    "    filename = match_obj.group('output')\n",
    "    with open(file, 'rb') as fp:\n",
    "        dict = pickle.load(fp)\n",
    "        embeddings_data[filename] = dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.clustering_helpers import dbscan_loop, kmeans_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:45:19,537 - INFO     | __main__   | GLOVE\n",
      "2023-05-30 17:45:19,538 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:45:21,253 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:45:21,799 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:45:22,031 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 17:45:22,272 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 17:45:22,524 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 17:45:23,883 - INFO     | __main__   | MPNET\n",
      "2023-05-30 17:45:23,884 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:45:28,904 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:45:33,868 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:45:38,687 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 17:45:42,755 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 17:45:46,985 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 17:45:51,654 - INFO     | __main__   | DISTIL\n",
      "2023-05-30 17:45:51,655 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:45:55,820 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:46:00,756 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:46:05,149 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 17:46:09,563 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 17:46:14,149 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 17:46:18,599 - INFO     | __main__   | WIKI\n",
      "2023-05-30 17:46:18,602 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:46:20,293 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:46:20,917 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:46:21,219 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 17:46:21,512 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 17:46:21,819 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 17:46:23,543 - INFO     | __main__   | W2V\n",
      "2023-05-30 17:46:23,543 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:46:25,188 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:46:27,472 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:46:29,560 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 17:46:31,531 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 17:46:32,878 - INFO     | __main__   | ---LLAMA_7B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 28s, sys: 2min 15s, total: 9min 44s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dbscan_overall_results = {}\n",
    "for embeddings_model, embeddings_list in embeddings_data.items():\n",
    "    logger.info(f'{embeddings_model.upper()}')\n",
    "    for llm, embeddings in embeddings_list.items():\n",
    "        logger.info(f'---{llm.upper()}')\n",
    "        score, components, samples = dbscan_loop(data=embeddings,\n",
    "                                                 n_components_space=[2, 4, 8, 16, 32, 64, 100],\n",
    "                                                 min_samples_space = [5, 10, 15, 20])\n",
    "        \n",
    "        dbscan_overall_results[(embeddings_model, llm, str(components), str(samples))] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:52:37,430 - INFO     | __main__   | GLOVE\n",
      "2023-05-30 17:52:37,434 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:52:50,181 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:53:06,176 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:53:19,649 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 17:53:34,335 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 17:53:41,421 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 17:53:55,922 - INFO     | __main__   | MPNET\n",
      "2023-05-30 17:53:55,923 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:54:32,120 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:55:06,694 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:55:43,173 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 17:56:16,264 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 17:56:48,685 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 17:57:24,198 - INFO     | __main__   | DISTIL\n",
      "2023-05-30 17:57:24,199 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:58:05,188 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:58:45,772 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:59:26,887 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 18:00:07,497 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 18:00:47,101 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 18:01:27,994 - INFO     | __main__   | WIKI\n",
      "2023-05-30 18:01:27,995 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 18:01:39,786 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 18:01:56,751 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 18:02:12,753 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 18:02:27,946 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 18:02:35,422 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 18:02:51,524 - INFO     | __main__   | W2V\n",
      "2023-05-30 18:02:51,525 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 18:03:04,552 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 18:03:19,893 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 18:03:36,682 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 18:03:52,829 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 18:04:00,835 - INFO     | __main__   | ---LLAMA_7B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 17min 57s, sys: 12min 21s, total: 1h 30min 18s\n",
      "Wall time: 11min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmeans_overall_results = {}\n",
    "for embeddings_model, embeddings_list in embeddings_data.items():\n",
    "    logger.info(f'{embeddings_model.upper()}')\n",
    "    for llm, embeddings in embeddings_list.items():\n",
    "        logger.info(f'---{llm.upper()}')\n",
    "        score, components, iters, n_cluster, tols = kmeans_loop(data=embeddings,\n",
    "                                                                n_components_space=[2, 4, 8, 16, 32, 64, 100],\n",
    "                                                                n_clusters_space = [2, 3, 4, 5],\n",
    "                                                                max_iter_space = [100, 250, 500],\n",
    "                                                                tol_space = [1e-4, 1e-3, 1e-2, 1e-2]\n",
    "        kmeans_overall_results[(embeddings_model, llm, str(components), str(iters), str(n_cluster), str(tols))] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EmbeddingsModel</th>\n",
       "      <th>LLM</th>\n",
       "      <th>PCA</th>\n",
       "      <th>MIN_SAMPLES</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">glove</th>\n",
       "      <th>bloom</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.705346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-0.095829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.252066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">mpnet</th>\n",
       "      <th>bloom</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.752365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.353684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.272236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.305975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.322380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.365544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">distil</th>\n",
       "      <th>bloom</th>\n",
       "      <th>32</th>\n",
       "      <th>15</th>\n",
       "      <td>0.711649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.279281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>16</th>\n",
       "      <th>20</th>\n",
       "      <td>0.227626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.211128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.226327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.372967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">wiki</th>\n",
       "      <th>bloom</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.716908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-0.096226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.254866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">w2v</th>\n",
       "      <th>bloom</th>\n",
       "      <th>32</th>\n",
       "      <th>10</th>\n",
       "      <td>0.742011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.218870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.264345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.312116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.392577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.439634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Score\n",
       "EmbeddingsModel LLM         PCA MIN_SAMPLES          \n",
       "glove           bloom       16  5            0.705346\n",
       "                alpaca_3b   16  5           -0.095829\n",
       "                alpaca_770m 16  5                -inf\n",
       "                llama_13b   16  5                -inf\n",
       "                gpt4all     16  5                -inf\n",
       "                llama_7b    16  5            0.252066\n",
       "mpnet           bloom       16  5            0.752365\n",
       "                alpaca_3b   16  5            0.353684\n",
       "                alpaca_770m 16  5            0.272236\n",
       "                llama_13b   16  5            0.305975\n",
       "                gpt4all     16  5            0.322380\n",
       "                llama_7b    16  5            0.365544\n",
       "distil          bloom       32  15           0.711649\n",
       "                alpaca_3b   16  5            0.279281\n",
       "                alpaca_770m 16  20           0.227626\n",
       "                llama_13b   16  5            0.211128\n",
       "                gpt4all     16  5            0.226327\n",
       "                llama_7b    16  5            0.372967\n",
       "wiki            bloom       16  5            0.716908\n",
       "                alpaca_3b   16  5           -0.096226\n",
       "                alpaca_770m 16  5                -inf\n",
       "                llama_13b   16  5                -inf\n",
       "                gpt4all     16  5                -inf\n",
       "                llama_7b    16  5            0.254866\n",
       "w2v             bloom       32  10           0.742011\n",
       "                alpaca_3b   16  5            0.218870\n",
       "                alpaca_770m 16  5            0.264345\n",
       "                llama_13b   16  5            0.312116\n",
       "                gpt4all     16  5            0.392577\n",
       "                llama_7b    16  5            0.439634"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbscan_df = pd.DataFrame.from_dict(dbscan_overall_results, orient='index', columns=['Score'])\n",
    "dbscan_df.index = pd.MultiIndex.from_tuples(dbscan_df.index, names=['EmbeddingsModel', 'LLM', 'PCA', 'MIN_SAMPLES'])\n",
    "\n",
    "# Display the DataFrame\n",
    "display(dbscan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EmbeddingsModel</th>\n",
       "      <th>LLM</th>\n",
       "      <th>PCA</th>\n",
       "      <th>MAX_ITERS</th>\n",
       "      <th>CLUSTERS</th>\n",
       "      <th>TOL</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">glove</th>\n",
       "      <th>bloom</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.757382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.144175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.463143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.131586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>32</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.130505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.362397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">mpnet</th>\n",
       "      <th>bloom</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.779275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.206025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>32</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.005050000000000001</th>\n",
       "      <td>0.170061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.115189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.489066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.357098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">distil</th>\n",
       "      <th>bloom</th>\n",
       "      <th>32</th>\n",
       "      <th>100</th>\n",
       "      <th>4</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.737272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.098994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.149407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>32</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.087967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>32</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.007525000000000001</th>\n",
       "      <td>0.182673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.362837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">wiki</th>\n",
       "      <th>bloom</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.756013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.150221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.162413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.142147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.119297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.449177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">w2v</th>\n",
       "      <th>bloom</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.749174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.135286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.124184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>32</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.121197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.096535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.472542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Score\n",
       "EmbeddingsModel LLM         PCA MAX_ITERS CLUSTERS TOL                           \n",
       "glove           bloom       16  100       3        0.0001                0.757382\n",
       "                alpaca_3b   16  100       2        0.0001                0.144175\n",
       "                alpaca_770m 64  100       2        0.0001                0.463143\n",
       "                llama_13b   64  100       2        0.0001                0.131586\n",
       "                gpt4all     32  100       2        0.0001                0.130505\n",
       "                llama_7b    16  100       2        0.0001                0.362397\n",
       "mpnet           bloom       16  100       2        0.0001                0.779275\n",
       "                alpaca_3b   16  100       2        0.0001                0.206025\n",
       "                alpaca_770m 32  100       3        0.005050000000000001  0.170061\n",
       "                llama_13b   64  100       3        0.0001                0.115189\n",
       "                gpt4all     64  100       2        0.0001                0.489066\n",
       "                llama_7b    16  100       2        0.0001                0.357098\n",
       "distil          bloom       32  100       4        0.0001                0.737272\n",
       "                alpaca_3b   64  100       2        0.0001                0.098994\n",
       "                alpaca_770m 64  100       3        0.0001                0.149407\n",
       "                llama_13b   32  100       2        0.0001                0.087967\n",
       "                gpt4all     32  100       3        0.007525000000000001  0.182673\n",
       "                llama_7b    16  100       2        0.0001                0.362837\n",
       "wiki            bloom       16  100       3        0.0001                0.756013\n",
       "                alpaca_3b   16  100       2        0.0001                0.150221\n",
       "                alpaca_770m 64  100       2        0.0001                0.162413\n",
       "                llama_13b   64  100       2        0.0001                0.142147\n",
       "                gpt4all     16  100       2        0.0001                0.119297\n",
       "                llama_7b    16  100       2        0.0001                0.449177\n",
       "w2v             bloom       16  100       3        0.0001                0.749174\n",
       "                alpaca_3b   16  100       3        0.0001                0.135286\n",
       "                alpaca_770m 16  100       2        0.0001                0.124184\n",
       "                llama_13b   32  100       2        0.0001                0.121197\n",
       "                gpt4all     16  100       2        0.0001                0.096535\n",
       "                llama_7b    16  100       2        0.0001                0.472542"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kmeans_df = pd.DataFrame.from_dict(kmeans_overall_results, orient='index', columns=['Score'])\n",
    "kmeans_df.index = pd.MultiIndex.from_tuples(kmeans_df.index, names=['EmbeddingsModel',\n",
    "                                                                    'LLM',\n",
    "                                                                    'PCA',\n",
    "                                                                    'MAX_ITERS',\n",
    "                                                                    'CLUSTERS',\n",
    "                                                                    'TOL'])\n",
    "\n",
    "# Display the DataFrame\n",
    "display(kmeans_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 23:06:07,702 - INFO     | config     | Loading environment variables\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.clustering import ClusteringModel\n",
    "from helpers.clustering_helpers import dbscan_loop, kmeans_loop, get_best_scores\n",
    "\n",
    "import pickle\n",
    "with open(f'embeddings/2000T_embeddings_202375.pkl', 'rb') as f:\n",
    "        embeddings_dict = pickle.load(f)\n",
    "\n",
    "df = pd.read_parquet('full_data_202375.parquet')\n",
    "df_new = df.drop(columns=['gpt-3.5-turbo_kmeans',\n",
    "                          'alpaca_kmeans',\n",
    "                          'gpt4all_kmeans',\n",
    "                          'gpt-3.5-turbo_dbscan',\n",
    "                          'alpaca_dbscan'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 23:06:08,455 - INFO     | __main__   | GPT-3.5-TURBO\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/lorenzo/Documents/repos/msc-thesis-llm-clustering/clustering.ipynb Cell 13\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzo/Documents/repos/msc-thesis-llm-clustering/clustering.ipynb#X14sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m llm, embeddings \u001b[39min\u001b[39;00m embeddings_dict\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzo/Documents/repos/msc-thesis-llm-clustering/clustering.ipynb#X14sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mllm\u001b[39m.\u001b[39mupper()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lorenzo/Documents/repos/msc-thesis-llm-clustering/clustering.ipynb#X14sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     results \u001b[39m=\u001b[39m kmeans_loop(data\u001b[39m=\u001b[39;49membeddings,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzo/Documents/repos/msc-thesis-llm-clustering/clustering.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                           n_components_space\u001b[39m=\u001b[39;49m[\u001b[39mNone\u001b[39;49;00m, \u001b[39m0.80\u001b[39;49m, \u001b[39m0.90\u001b[39;49m, \u001b[39m0.95\u001b[39;49m, \u001b[39m0.99\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzo/Documents/repos/msc-thesis-llm-clustering/clustering.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                           n_clusters_space \u001b[39m=\u001b[39;49m \u001b[39mlist\u001b[39;49m(np\u001b[39m.\u001b[39;49mlinspace(\u001b[39m1\u001b[39;49m, \u001b[39m10\u001b[39;49m, \u001b[39m10\u001b[39;49m, dtype\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mint\u001b[39;49m\u001b[39m'\u001b[39;49m)),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lorenzo/Documents/repos/msc-thesis-llm-clustering/clustering.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                           max_iter_space \u001b[39m=\u001b[39;49m [\u001b[39m250\u001b[39;49m, \u001b[39m500\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzo/Documents/repos/msc-thesis-llm-clustering/clustering.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     best_results_kmeans[llm] \u001b[39m=\u001b[39m get_best_scores(results\u001b[39m=\u001b[39mresults, model_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mkmeans\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lorenzo/Documents/repos/msc-thesis-llm-clustering/clustering.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     best_results_kmeans[llm][\u001b[39m'\u001b[39m\u001b[39moriginal_emb\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m embeddings\n",
      "File \u001b[0;32m~/Documents/repos/msc-thesis-llm-clustering/helpers/clustering_helpers.py:73\u001b[0m, in \u001b[0;36mkmeans_loop\u001b[0;34m(data, n_components_space, n_clusters_space, max_iter_space)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[39mfor\u001b[39;00m max_iter \u001b[39min\u001b[39;00m max_iter_space:\n\u001b[1;32m     68\u001b[0m     kmeans \u001b[39m=\u001b[39m ClusteringModel(model_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mkmeans\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     69\u001b[0m                              n_clusters\u001b[39m=\u001b[39mn_clusters,\n\u001b[1;32m     70\u001b[0m                              max_iter\u001b[39m=\u001b[39mmax_iter,\n\u001b[1;32m     71\u001b[0m                              n_init\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 73\u001b[0m     kmeans\u001b[39m.\u001b[39;49mfit_predict(embeddings\u001b[39m=\u001b[39;49mdata, pca_flag\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, n_components\u001b[39m=\u001b[39;49mn_components)\n\u001b[1;32m     75\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         scores \u001b[39m=\u001b[39m silhouette_score(data, kmeans\u001b[39m.\u001b[39mclusters, metric\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39meuclidean\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/repos/msc-thesis-llm-clustering/models/clustering.py:50\u001b[0m, in \u001b[0;36mClusteringModel.fit_predict\u001b[0;34m(self, embeddings, pca_flag, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPerforming PCA with \u001b[39m\u001b[39m{\u001b[39;00mkwargs[\u001b[39m\"\u001b[39m\u001b[39mn_components\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m components...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39mkwargs[\u001b[39m'\u001b[39m\u001b[39mn_components\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 50\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpca\u001b[39m.\u001b[39;49mfit_transform(embeddings)\n\u001b[1;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactual_components \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpca\u001b[39m.\u001b[39mn_components_\n\u001b[1;32m     54\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mfit(embeddings)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:462\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[1;32m    441\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mC-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    460\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m--> 462\u001b[0m U, S, Vt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[1;32m    463\u001b[0m U \u001b[39m=\u001b[39m U[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components_]\n\u001b[1;32m    465\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhiten:\n\u001b[1;32m    466\u001b[0m     \u001b[39m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:512\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[39m# Call different fits for either full or truncated SVD\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mfull\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 512\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_full(X, n_components)\n\u001b[1;32m    513\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39marpack\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrandomized\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    514\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_truncated(X, n_components, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_svd_solver)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/sklearn/decomposition/_pca.py:536\u001b[0m, in \u001b[0;36mPCA._fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(X, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m    534\u001b[0m X \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmean_\n\u001b[0;32m--> 536\u001b[0m U, S, Vt \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39;49msvd(X, full_matrices\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    537\u001b[0m \u001b[39m# flip eigenvectors' sign to enforce deterministic output\u001b[39;00m\n\u001b[1;32m    538\u001b[0m U, Vt \u001b[39m=\u001b[39m svd_flip(U, Vt)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/scipy/linalg/_decomp_svd.py:127\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, overwrite_a, check_finite, lapack_driver)\u001b[0m\n\u001b[1;32m    123\u001b[0m lwork \u001b[39m=\u001b[39m _compute_lwork(gesXd_lwork, a1\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], a1\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],\n\u001b[1;32m    124\u001b[0m                        compute_uv\u001b[39m=\u001b[39mcompute_uv, full_matrices\u001b[39m=\u001b[39mfull_matrices)\n\u001b[1;32m    126\u001b[0m \u001b[39m# perform decomposition\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m u, s, v, info \u001b[39m=\u001b[39m gesXd(a1, compute_uv\u001b[39m=\u001b[39;49mcompute_uv, lwork\u001b[39m=\u001b[39;49mlwork,\n\u001b[1;32m    128\u001b[0m                       full_matrices\u001b[39m=\u001b[39;49mfull_matrices, overwrite_a\u001b[39m=\u001b[39;49moverwrite_a)\n\u001b[1;32m    130\u001b[0m \u001b[39mif\u001b[39;00m info \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    131\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSVD did not converge\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# kmeans\n",
    "\n",
    "best_results_kmeans = {}\n",
    "for llm, embeddings in embeddings_dict.items():\n",
    "    logger.info(f'{llm.upper()}')\n",
    "    results = kmeans_loop(data=embeddings,\n",
    "                          n_components_space=[None, 0.80, 0.90, 0.95, 0.99],\n",
    "                          n_clusters_space = list(np.linspace(1, 10, 10, dtype='int')),\n",
    "                          max_iter_space = [250, 500])\n",
    "    \n",
    "    best_results_kmeans[llm] = get_best_scores(results=results, model_name='kmeans')\n",
    "    best_results_kmeans[llm]['original_emb'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>n_components</th>\n",
       "      <th>actual_components</th>\n",
       "      <th>max_iter</th>\n",
       "      <th>n_clusters</th>\n",
       "      <th>original_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>0.119900</td>\n",
       "      <td>0.90</td>\n",
       "      <td>142</td>\n",
       "      <td>250</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-0.03887094, -0.11050342, -0.031814046, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca</th>\n",
       "      <td>0.114074</td>\n",
       "      <td>0.99</td>\n",
       "      <td>375</td>\n",
       "      <td>250</td>\n",
       "      <td>3</td>\n",
       "      <td>[[0.011134546, -0.08676946, -0.03891137, 0.060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <td>0.155368</td>\n",
       "      <td>NaN</td>\n",
       "      <td>768</td>\n",
       "      <td>250</td>\n",
       "      <td>2</td>\n",
       "      <td>[[-0.02282622, -0.08779901, -0.021268817, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  score  n_components  actual_components  max_iter  \\\n",
       "gpt-3.5-turbo  0.119900          0.90                142       250   \n",
       "alpaca         0.114074          0.99                375       250   \n",
       "gpt4all        0.155368           NaN                768       250   \n",
       "\n",
       "               n_clusters                                       original_emb  \n",
       "gpt-3.5-turbo           2  [[-0.03887094, -0.11050342, -0.031814046, 0.02...  \n",
       "alpaca                  3  [[0.011134546, -0.08676946, -0.03891137, 0.060...  \n",
       "gpt4all                 2  [[-0.02282622, -0.08779901, -0.021268817, -0.0...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(best_results_kmeans, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 22:36:09,430 - INFO     | __main__   | GPT-3.5-TURBO\n",
      "2023-10-03 22:36:10,054 - INFO     | __main__   | ALPACA\n",
      "2023-10-03 22:36:11,121 - INFO     | __main__   | GPT4ALL\n"
     ]
    }
   ],
   "source": [
    "final_kmeans_emb = {}\n",
    "kmeans_clusters = []\n",
    "for llm, params in best_results_kmeans.items():\n",
    "    logger.info(llm.upper())\n",
    "    kmeans = ClusteringModel(model_name='kmeans',\n",
    "                             n_init='auto',\n",
    "                             max_iter=params['max_iter'],\n",
    "                             n_clusters=params['n_clusters'])\n",
    "    kmeans.fit_predict(embeddings=params['original_emb'],\n",
    "                       pca_flag=True,\n",
    "                       n_components=params['n_components'])\n",
    "    kmeans_clusters.append(kmeans.clusters)\n",
    "    \n",
    "    final_kmeans_emb[llm] = (params['original_emb'], kmeans.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['gpt-3.5-turbo_kmeans'] = kmeans_clusters[0]\n",
    "df_new['alpaca_kmeans'] = kmeans_clusters[1]\n",
    "df_new['gpt4all_kmeans'] = kmeans_clusters[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 22:53:34,964 - INFO     | __main__   | GPT-3.5-TURBO\n",
      "2023-10-03 22:53:35,967 - INFO     | helpers.clustering_helpers | Found them\n",
      "2023-10-03 22:54:59,996 - INFO     | helpers.clustering_helpers | Found them\n",
      "2023-10-03 22:55:21,684 - INFO     | helpers.clustering_helpers | Found them\n",
      "2023-10-03 22:55:45,456 - INFO     | helpers.clustering_helpers | Found them\n",
      "2023-10-03 22:56:08,768 - INFO     | helpers.clustering_helpers | Best Score: 0.09637953341007233\n",
      "2023-10-03 22:56:08,779 - INFO     | __main__   | ALPACA\n",
      "2023-10-03 22:56:09,773 - INFO     | helpers.clustering_helpers | Found them\n",
      "2023-10-03 22:56:10,766 - INFO     | helpers.clustering_helpers | Found them\n",
      "2023-10-03 22:57:26,684 - INFO     | helpers.clustering_helpers | Found them\n",
      "2023-10-03 22:57:53,780 - INFO     | helpers.clustering_helpers | Found them\n",
      "2023-10-03 22:58:19,847 - INFO     | helpers.clustering_helpers | Found them\n",
      "2023-10-03 22:58:20,875 - INFO     | helpers.clustering_helpers | Found them\n",
      "2023-10-03 22:58:47,456 - INFO     | helpers.clustering_helpers | Found them\n",
      "2023-10-03 22:58:48,663 - INFO     | helpers.clustering_helpers | Found them\n",
      "2023-10-03 22:59:16,391 - INFO     | helpers.clustering_helpers | Best Score: 0.14965079724788666\n",
      "2023-10-03 22:59:16,392 - INFO     | __main__   | GPT4ALL\n",
      "2023-10-03 23:01:56,956 - WARNING  | helpers.clustering_helpers | attempt to get argmax of an empty sequence\n"
     ]
    }
   ],
   "source": [
    "# dbscan\n",
    "\n",
    "best_results_dbscan = {}\n",
    "for llm, embeddings in embeddings_dict.items():\n",
    "    logger.info(f'{llm.upper()}')\n",
    "    results = dbscan_loop(data=embeddings,\n",
    "                          n_components_space=[None, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99],\n",
    "                          eps_space= [0.5, 0.6, 0.7, 0.8, 0.9],\n",
    "                          min_samples_space=[5, 25, 50, 75, 100])\n",
    "    \n",
    "    best_results_dbscan[llm] = get_best_scores(results=results, model_name='dbscan')\n",
    "    best_results_dbscan[llm]['original_emb'] = embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>n_components</th>\n",
       "      <th>actual_components</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>eps</th>\n",
       "      <th>original_emb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-3.5-turbo</th>\n",
       "      <td>0.096380</td>\n",
       "      <td>0.90</td>\n",
       "      <td>142.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>[[-0.03887094, -0.11050342, -0.031814046, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca</th>\n",
       "      <td>0.149651</td>\n",
       "      <td>0.95</td>\n",
       "      <td>203.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>[[0.011134546, -0.08676946, -0.03891137, 0.060...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[-0.02282622, -0.08779901, -0.021268817, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  score  n_components  actual_components  min_samples  eps  \\\n",
       "gpt-3.5-turbo  0.096380          0.90              142.0          5.0  0.5   \n",
       "alpaca         0.149651          0.95              203.0          5.0  0.6   \n",
       "gpt4all             NaN           NaN                NaN          NaN  NaN   \n",
       "\n",
       "                                                    original_emb  \n",
       "gpt-3.5-turbo  [[-0.03887094, -0.11050342, -0.031814046, 0.02...  \n",
       "alpaca         [[0.011134546, -0.08676946, -0.03891137, 0.060...  \n",
       "gpt4all        [[-0.02282622, -0.08779901, -0.021268817, -0.0...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(best_results_dbscan, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-03 23:05:08,142 - INFO     | __main__   | GPT-3.5-TURBO\n",
      "2023-10-03 23:05:08,708 - INFO     | __main__   | ALPACA\n",
      "2023-10-03 23:05:09,507 - INFO     | __main__   | GPT4ALL\n",
      "2023-10-03 23:05:09,507 - WARNING  | __main__   | Not Clusters Found for GPT4ALL\n"
     ]
    }
   ],
   "source": [
    "final_dbscan_emb = {}\n",
    "dbscan_clusters = []\n",
    "for llm, params in best_results_dbscan.items():\n",
    "    logger.info(llm.upper())\n",
    "    try:\n",
    "        dbscan = ClusteringModel(model_name='dbscan',\n",
    "                                 eps=params['eps'],\n",
    "                                 min_samples=params['min_samples'],\n",
    "                                 metric='euclidean')\n",
    "        dbscan.fit_predict(embeddings=params['original_emb'],\n",
    "                           pca_flag=True,\n",
    "                           n_components=params['n_components'])\n",
    "        dbscan_clusters.append(dbscan.clusters)\n",
    "        \n",
    "        final_dbscan_emb[llm] = (params['original_emb'], dbscan.embeddings)\n",
    "    except Exception as e:\n",
    "        logger.warning(f'Not Clusters Found for {llm.upper()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new['gpt-3.5-turbo_dbscan'] = dbscan_clusters[0]\n",
    "df_new['alpaca_dbscan'] = dbscan_clusters[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-3.5-turbo': None}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
