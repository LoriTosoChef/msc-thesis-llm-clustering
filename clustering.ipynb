{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:45:18,560 - INFO     | config     | Loading environment variables\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:45:18,906 - INFO     | __main__   | Loading embeddings/glove_embeddings_test.pkl\n",
      "2023-05-30 17:45:18,909 - INFO     | __main__   | Loading embeddings/mpnet_embeddings_test.pkl\n",
      "2023-05-30 17:45:18,911 - INFO     | __main__   | Loading embeddings/distil_embeddings_test.pkl\n",
      "2023-05-30 17:45:18,914 - INFO     | __main__   | Loading embeddings/wiki_embeddings_test.pkl\n",
      "2023-05-30 17:45:18,916 - INFO     | __main__   | Loading embeddings/w2v_embeddings_test.pkl\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "files = glob.glob('embeddings/*_test.pkl')\n",
    "embeddings_data = {}\n",
    "\n",
    "for file in files:\n",
    "    logger.info(f'Loading {file}')\n",
    "    match_obj = re.search(r'/(?P<output>[^_/]+)_', file)\n",
    "    filename = match_obj.group('output')\n",
    "    with open(file, 'rb') as fp:\n",
    "        dict = pickle.load(fp)\n",
    "        embeddings_data[filename] = dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.clustering_helpers import clustering_scores, dbscan_loop, kmeans_loop\n",
    "from helpers.data_viz import plot_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:45:19,537 - INFO     | __main__   | GLOVE\n",
      "2023-05-30 17:45:19,538 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:45:21,253 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:45:21,799 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:45:22,031 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 17:45:22,272 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 17:45:22,524 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 17:45:23,883 - INFO     | __main__   | MPNET\n",
      "2023-05-30 17:45:23,884 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:45:28,904 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:45:33,868 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:45:38,687 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 17:45:42,755 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 17:45:46,985 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 17:45:51,654 - INFO     | __main__   | DISTIL\n",
      "2023-05-30 17:45:51,655 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:45:55,820 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:46:00,756 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:46:05,149 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 17:46:09,563 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 17:46:14,149 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 17:46:18,599 - INFO     | __main__   | WIKI\n",
      "2023-05-30 17:46:18,602 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:46:20,293 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:46:20,917 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:46:21,219 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 17:46:21,512 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 17:46:21,819 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 17:46:23,543 - INFO     | __main__   | W2V\n",
      "2023-05-30 17:46:23,543 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:46:25,188 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:46:27,472 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:46:29,560 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 17:46:31,531 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 17:46:32,878 - INFO     | __main__   | ---LLAMA_7B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 28s, sys: 2min 15s, total: 9min 44s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dbscan_overall_results = {}\n",
    "for embeddings_model, embeddings_list in embeddings_data.items():\n",
    "    logger.info(f'{embeddings_model.upper()}')\n",
    "    for llm, embeddings in embeddings_list.items():\n",
    "        logger.info(f'---{llm.upper()}')\n",
    "        score, components, samples = dbscan_loop(data=embeddings,\n",
    "                                                 n_components_space=[16, 32, 64, 100],\n",
    "                                                 min_samples_space = [5, 10, 15, 20])\n",
    "        \n",
    "        dbscan_overall_results[(embeddings_model, llm, str(components), str(samples))] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-30 17:52:37,430 - INFO     | __main__   | GLOVE\n",
      "2023-05-30 17:52:37,434 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:52:50,181 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:53:06,176 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:53:19,649 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 17:53:34,335 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 17:53:41,421 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 17:53:55,922 - INFO     | __main__   | MPNET\n",
      "2023-05-30 17:53:55,923 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:54:32,120 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:55:06,694 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:55:43,173 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 17:56:16,264 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 17:56:48,685 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 17:57:24,198 - INFO     | __main__   | DISTIL\n",
      "2023-05-30 17:57:24,199 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 17:58:05,188 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 17:58:45,772 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 17:59:26,887 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 18:00:07,497 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 18:00:47,101 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 18:01:27,994 - INFO     | __main__   | WIKI\n",
      "2023-05-30 18:01:27,995 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 18:01:39,786 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 18:01:56,751 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 18:02:12,753 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 18:02:27,946 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 18:02:35,422 - INFO     | __main__   | ---LLAMA_7B\n",
      "2023-05-30 18:02:51,524 - INFO     | __main__   | W2V\n",
      "2023-05-30 18:02:51,525 - INFO     | __main__   | ---BLOOM\n",
      "2023-05-30 18:03:04,552 - INFO     | __main__   | ---ALPACA_3B\n",
      "2023-05-30 18:03:19,893 - INFO     | __main__   | ---ALPACA_770M\n",
      "2023-05-30 18:03:36,682 - INFO     | __main__   | ---LLAMA_13B\n",
      "2023-05-30 18:03:52,829 - INFO     | __main__   | ---GPT4ALL\n",
      "2023-05-30 18:04:00,835 - INFO     | __main__   | ---LLAMA_7B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 17min 57s, sys: 12min 21s, total: 1h 30min 18s\n",
      "Wall time: 11min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmeans_overall_results = {}\n",
    "for embeddings_model, embeddings_list in embeddings_data.items():\n",
    "    logger.info(f'{embeddings_model.upper()}')\n",
    "    for llm, embeddings in embeddings_list.items():\n",
    "        logger.info(f'---{llm.upper()}')\n",
    "        score, components, iters, n_cluster, tols = kmeans_loop(data=embeddings,\n",
    "                                                                n_components_space=[16, 32, 64, 100],\n",
    "                                                                n_clusters_space = [2, 3, 4],\n",
    "                                                                max_iter_space = [100, 250],\n",
    "                                                                tol_space = [1e-4, 1e-3, 1e-2, 1e-2]\n",
    "        kmeans_overall_results[(embeddings_model, llm, str(components), str(iters), str(n_cluster), str(tols))] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EmbeddingsModel</th>\n",
       "      <th>LLM</th>\n",
       "      <th>PCA</th>\n",
       "      <th>MIN_SAMPLES</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">glove</th>\n",
       "      <th>bloom</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.705346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-0.095829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.252066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">mpnet</th>\n",
       "      <th>bloom</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.752365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.353684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.272236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.305975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.322380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.365544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">distil</th>\n",
       "      <th>bloom</th>\n",
       "      <th>32</th>\n",
       "      <th>15</th>\n",
       "      <td>0.711649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.279281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>16</th>\n",
       "      <th>20</th>\n",
       "      <td>0.227626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.211128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.226327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.372967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">wiki</th>\n",
       "      <th>bloom</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.716908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-0.096226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>-inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.254866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">w2v</th>\n",
       "      <th>bloom</th>\n",
       "      <th>32</th>\n",
       "      <th>10</th>\n",
       "      <td>0.742011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.218870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.264345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.312116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.392577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <td>0.439634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Score\n",
       "EmbeddingsModel LLM         PCA MIN_SAMPLES          \n",
       "glove           bloom       16  5            0.705346\n",
       "                alpaca_3b   16  5           -0.095829\n",
       "                alpaca_770m 16  5                -inf\n",
       "                llama_13b   16  5                -inf\n",
       "                gpt4all     16  5                -inf\n",
       "                llama_7b    16  5            0.252066\n",
       "mpnet           bloom       16  5            0.752365\n",
       "                alpaca_3b   16  5            0.353684\n",
       "                alpaca_770m 16  5            0.272236\n",
       "                llama_13b   16  5            0.305975\n",
       "                gpt4all     16  5            0.322380\n",
       "                llama_7b    16  5            0.365544\n",
       "distil          bloom       32  15           0.711649\n",
       "                alpaca_3b   16  5            0.279281\n",
       "                alpaca_770m 16  20           0.227626\n",
       "                llama_13b   16  5            0.211128\n",
       "                gpt4all     16  5            0.226327\n",
       "                llama_7b    16  5            0.372967\n",
       "wiki            bloom       16  5            0.716908\n",
       "                alpaca_3b   16  5           -0.096226\n",
       "                alpaca_770m 16  5                -inf\n",
       "                llama_13b   16  5                -inf\n",
       "                gpt4all     16  5                -inf\n",
       "                llama_7b    16  5            0.254866\n",
       "w2v             bloom       32  10           0.742011\n",
       "                alpaca_3b   16  5            0.218870\n",
       "                alpaca_770m 16  5            0.264345\n",
       "                llama_13b   16  5            0.312116\n",
       "                gpt4all     16  5            0.392577\n",
       "                llama_7b    16  5            0.439634"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dbscan_df = pd.DataFrame.from_dict(dbscan_overall_results, orient='index', columns=['Score'])\n",
    "dbscan_df.index = pd.MultiIndex.from_tuples(dbscan_df.index, names=['EmbeddingsModel', 'LLM', 'PCA', 'MIN_SAMPLES'])\n",
    "\n",
    "# Display the DataFrame\n",
    "display(dbscan_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EmbeddingsModel</th>\n",
       "      <th>LLM</th>\n",
       "      <th>PCA</th>\n",
       "      <th>MAX_ITERS</th>\n",
       "      <th>CLUSTERS</th>\n",
       "      <th>TOL</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">glove</th>\n",
       "      <th>bloom</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.757382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.144175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.463143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.131586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>32</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.130505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.362397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">mpnet</th>\n",
       "      <th>bloom</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.779275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.206025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>32</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.005050000000000001</th>\n",
       "      <td>0.170061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.115189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.489066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.357098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">distil</th>\n",
       "      <th>bloom</th>\n",
       "      <th>32</th>\n",
       "      <th>100</th>\n",
       "      <th>4</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.737272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.098994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.149407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>32</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.087967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>32</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.007525000000000001</th>\n",
       "      <td>0.182673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.362837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">wiki</th>\n",
       "      <th>bloom</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.756013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.150221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.162413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>64</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.142147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.119297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.449177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">w2v</th>\n",
       "      <th>bloom</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.749174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>3</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.135286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.124184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_13b</th>\n",
       "      <th>32</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.121197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt4all</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.096535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama_7b</th>\n",
       "      <th>16</th>\n",
       "      <th>100</th>\n",
       "      <th>2</th>\n",
       "      <th>0.0001</th>\n",
       "      <td>0.472542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Score\n",
       "EmbeddingsModel LLM         PCA MAX_ITERS CLUSTERS TOL                           \n",
       "glove           bloom       16  100       3        0.0001                0.757382\n",
       "                alpaca_3b   16  100       2        0.0001                0.144175\n",
       "                alpaca_770m 64  100       2        0.0001                0.463143\n",
       "                llama_13b   64  100       2        0.0001                0.131586\n",
       "                gpt4all     32  100       2        0.0001                0.130505\n",
       "                llama_7b    16  100       2        0.0001                0.362397\n",
       "mpnet           bloom       16  100       2        0.0001                0.779275\n",
       "                alpaca_3b   16  100       2        0.0001                0.206025\n",
       "                alpaca_770m 32  100       3        0.005050000000000001  0.170061\n",
       "                llama_13b   64  100       3        0.0001                0.115189\n",
       "                gpt4all     64  100       2        0.0001                0.489066\n",
       "                llama_7b    16  100       2        0.0001                0.357098\n",
       "distil          bloom       32  100       4        0.0001                0.737272\n",
       "                alpaca_3b   64  100       2        0.0001                0.098994\n",
       "                alpaca_770m 64  100       3        0.0001                0.149407\n",
       "                llama_13b   32  100       2        0.0001                0.087967\n",
       "                gpt4all     32  100       3        0.007525000000000001  0.182673\n",
       "                llama_7b    16  100       2        0.0001                0.362837\n",
       "wiki            bloom       16  100       3        0.0001                0.756013\n",
       "                alpaca_3b   16  100       2        0.0001                0.150221\n",
       "                alpaca_770m 64  100       2        0.0001                0.162413\n",
       "                llama_13b   64  100       2        0.0001                0.142147\n",
       "                gpt4all     16  100       2        0.0001                0.119297\n",
       "                llama_7b    16  100       2        0.0001                0.449177\n",
       "w2v             bloom       16  100       3        0.0001                0.749174\n",
       "                alpaca_3b   16  100       3        0.0001                0.135286\n",
       "                alpaca_770m 16  100       2        0.0001                0.124184\n",
       "                llama_13b   32  100       2        0.0001                0.121197\n",
       "                gpt4all     16  100       2        0.0001                0.096535\n",
       "                llama_7b    16  100       2        0.0001                0.472542"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kmeans_df = pd.DataFrame.from_dict(kmeans_overall_results, orient='index', columns=['Score'])\n",
    "kmeans_df.index = pd.MultiIndex.from_tuples(kmeans_df.index, names=['EmbeddingsModel',\n",
    "                                                                    'LLM',\n",
    "                                                                    'PCA',\n",
    "                                                                    'MAX_ITERS',\n",
    "                                                                    'CLUSTERS',\n",
    "                                                                    'TOL'])\n",
    "\n",
    "# Display the DataFrame\n",
    "display(kmeans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
