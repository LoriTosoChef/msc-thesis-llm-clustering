{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bb88847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from models.gpt4all import GPT4ALL\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cce37968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temp': 1e-10, 'ctx_size': 2048, 'threads': 4}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4all = GPT4ALL()\n",
    "gpt4all.model.decoder_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1016d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_load: ggml ctx size = 6065.35 MB\n",
      "llama_model_load: memory_size =  2048.00 MB, n_mem = 65536\n",
      "llama_model_load: loading model part 1/1 from '/Users/lorenzo/.nomic/gpt4all-lora-quantized.bin'\n",
      "llama_model_load: .................................... done\n",
      "llama_model_load: model size =  4017.27 MB / num tensors = 291\n"
     ]
    }
   ],
   "source": [
    "gpt4all.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "353fc807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi how are you?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4all.init_prompt('hi how are you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55f979d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm doing great thanks for asking! How about yourself?\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4all.generate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b72f1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import llamacpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b5ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def progress_callback(progress):\n",
    "    print(\"Progress: {:.2f}%\".format(progress * 100))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "params = llamacpp.InferenceParams.default_with_callback(progress_callback)\n",
    "params.path_model = '/Users/lorenzo/.nomic/gpt4all-lora-quantized.bin'\n",
    "model = llamacpp.LlamaInference(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cce66e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
