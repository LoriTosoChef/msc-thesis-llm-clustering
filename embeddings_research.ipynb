{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>bloom</th>\n",
       "      <th>alpaca_3b</th>\n",
       "      <th>alpaca_770m</th>\n",
       "      <th>llama_13b</th>\n",
       "      <th>gpt4all</th>\n",
       "      <th>llama_7b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1642025557511532545</td>\n",
       "      <td>the white paws, the cute collar, the tongue, t...</td>\n",
       "      <td>Yes, the above tweet is a potential lead. The...</td>\n",
       "      <td>Yes, this tweet is a potential lead because it...</td>\n",
       "      <td>Yes, the tweet is a potential lead because it ...</td>\n",
       "      <td>1. What is your analysis of the tweet in terms...</td>\n",
       "      <td>\\n\\nAnswer:\\n\\nYes, the above tweet is a poten...</td>\n",
       "      <td>Yes. The reason is that it has all the charac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          full_text  \\\n",
       "0  1642025557511532545  the white paws, the cute collar, the tongue, t...   \n",
       "\n",
       "                                               bloom  \\\n",
       "0   Yes, the above tweet is a potential lead. The...   \n",
       "\n",
       "                                           alpaca_3b  \\\n",
       "0  Yes, this tweet is a potential lead because it...   \n",
       "\n",
       "                                         alpaca_770m  \\\n",
       "0  Yes, the tweet is a potential lead because it ...   \n",
       "\n",
       "                                           llama_13b  \\\n",
       "0  1. What is your analysis of the tweet in terms...   \n",
       "\n",
       "                                             gpt4all  \\\n",
       "0  \\n\\nAnswer:\\n\\nYes, the above tweet is a poten...   \n",
       "\n",
       "                                            llama_7b  \n",
       "0   Yes. The reason is that it has all the charac...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = pd.read_parquet('outputs/0S_100T_all_models_202345.parquet')\n",
    "outputs.head(1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "Testing on ```llama_7b``` outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_col = 'llama_7b'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence embeddings\n",
    "\n",
    "Using sentence embeddings out of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:07:09,958 - INFO     | config     | Loading environment variables\n"
     ]
    }
   ],
   "source": [
    "from models.embeddings import SentenceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:07:11,578 - INFO     | models.embeddings | Initializing MPNET for Sentence Embeddings\n",
      "2023-04-18 16:07:11,578 - INFO     | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-mpnet-base-v2\n",
      "2023-04-18 16:07:12,785 - INFO     | sentence_transformers.SentenceTransformer | Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "mpnet = SentenceEmbeddings(name='mpnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:07:12,806 - INFO     | models.embeddings | MPNET - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf16bff40594eebba319ba63f5525c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_generations = outputs[model_col]\n",
    "mpnet_embeddings = mpnet.generate_embeddings(input_texts=sentence_generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of size (100, 768)\n",
      "Examples: 100\n",
      "Embeddings: 768\n"
     ]
    }
   ],
   "source": [
    "print(f'Vector of size {mpnet_embeddings.shape}')\n",
    "print(f'Examples: {mpnet_embeddings.shape[0]}')\n",
    "print(f'Embeddings: {mpnet_embeddings.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04991404,  0.01245025, -0.03698337,  0.0051044 , -0.00996805,\n",
       "        0.04320958, -0.00838856, -0.01815155,  0.00822093, -0.04142584,\n",
       "        0.01140831, -0.04896618, -0.00486582,  0.09946115,  0.01967317,\n",
       "        0.01221775,  0.00650522, -0.0036213 ,  0.06752104,  0.03149004,\n",
       "        0.01869595,  0.04843361, -0.00307424,  0.02203452, -0.03022938],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpnet_embeddings[0][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:07:20,882 - INFO     | models.embeddings | Initializing DISTILROBERTA for Sentence Embeddings\n",
      "2023-04-18 16:07:20,883 - INFO     | sentence_transformers.SentenceTransformer | Load pretrained SentenceTransformer: all-distilroberta-v1\n",
      "2023-04-18 16:07:21,616 - INFO     | sentence_transformers.SentenceTransformer | Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "distilrberta = SentenceEmbeddings(name='distilroberta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:07:21,633 - INFO     | models.embeddings | DISTILROBERTA - Generating sentence embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb461533ade448abb9d817613dea130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_generations = outputs[model_col]\n",
    "distil_embeddings = distilrberta.generate_embeddings(input_texts=sentence_generations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of size (100, 768)\n",
      "# Examples: 100\n",
      "Embeddings size: 768\n"
     ]
    }
   ],
   "source": [
    "print(f'Vector of size {distil_embeddings.shape}')\n",
    "print(f'# Examples: {distil_embeddings.shape[0]}')\n",
    "print(f'Embeddings size: {distil_embeddings.shape[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03276022, -0.05949922, -0.01047634,  0.04310662,  0.02558028,\n",
       "        0.11160419, -0.04925827,  0.03003629, -0.00140462,  0.00830909,\n",
       "        0.01378632, -0.06636973, -0.01438876, -0.02891294, -0.04767688,\n",
       "       -0.03492078, -0.01642984,  0.01148561,  0.01943938, -0.02421685,\n",
       "       -0.01196974, -0.02823601, -0.02021303,  0.01467953, -0.01395709],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distil_embeddings[0][:25]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "\n",
    "Creating tokens, word embeddings and averaging them to create one vector per output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/lorenzo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/lorenzo/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from models.embeddings import WordEmbeddings\n",
    "from helpers.embeddings_helpers import clean_and_tokenize_text\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "STOPWORDS = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting text columns to string columns\n",
    "word_embeddings_df = outputs.copy()\n",
    "word_embeddings_df[model_col] = word_embeddings_df[model_col].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [yes, reason, characteristics, potential, lead...\n",
       "1     [yes, potential, lead, shows, person, posted, ...\n",
       "2     [yes, potential, lead, related, marketing, cus...\n",
       "3     [▪️, yes, nike, made, several, acquisitions, y...\n",
       "4     [potential, lead, contain, information, used, ...\n",
       "                            ...                        \n",
       "95    [tweet, potential, lead, information, person, ...\n",
       "96    [yes, potential, lead, news, article, decline,...\n",
       "97    [think, potential, lead, information, product,...\n",
       "98    [tweet, potential, lead, posted, user, interes...\n",
       "99    [would, say, related, topic, marketing, custom...\n",
       "Name: llama_7b, Length: 100, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['yes', 'reason', 'characteristics', 'potential', 'lead', 'right', 'combination', 'factors', 'cuteness', 'adorability', 'key', 'factors', 'marketing', 'customer', 'relationship', 'management', 'answer', 'question', 'based', 'context', 'context', 'marketing', 'customer', 'relationship', 'management', 'assistant', 'task', 'classify', 'given', 'tweet', 'either', 'potential', 'lead', 'provide', 'detailed', 'analysis', 'following', 'tweet', 'potential', 'lead', 'context', 'marketing', 'customer', 'relationship', 'management', 'tweet', 'white', 'paws', 'cute', 'collar', 'tongue', 'cute', 'red', 'eyeliner', 'adorable', 'hat', 'small', 'mullet', 'sweet', 'stare', 'pink', 'beans', 'roundness', 'body', 'question', 'tweet', 'potential', 'lead', 'yes', 'answer', 'yes', 'reason', 'characteristics', 'potential', 'lead', 'right', 'combination', 'factors', 'cuteness', 'adorability', 'key', 'factors', 'marketing', 'customer', 'relationship', 'management']\n"
     ]
    }
   ],
   "source": [
    "# creating word level tokens for each model output\n",
    "word_embeddings_df[model_col] = word_embeddings_df[model_col].map(lambda x: clean_and_tokenize_text(x, tokenizer=word_tokenize, stopwords=STOPWORDS))\n",
    "display(word_embeddings_df[model_col])\n",
    "print(f'Tokens: {word_embeddings_df[model_col].iloc[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:07:25,963 - INFO     | models.embeddings | Initializing GLOVE-TWITTER for Word Embeddings\n",
      "2023-04-18 16:07:26,210 - INFO     | gensim.models.keyedvectors | loading projection weights from /Users/lorenzo/gensim-data/glove-twitter-200/glove-twitter-200.gz\n",
      "2023-04-18 16:08:36,184 - INFO     | gensim.utils | KeyedVectors lifecycle event {'msg': 'loaded (1193514, 200) matrix of type float32 from /Users/lorenzo/gensim-data/glove-twitter-200/glove-twitter-200.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-04-18T16:08:36.184486', 'gensim': '4.3.1', 'python': '3.9.13 (main, Mar  3 2023, 13:16:29) \\n[Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-13.3.1-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "glove = WordEmbeddings(name='glove-twitter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:08:36,201 - INFO     | models.embeddings | GLOVE-TWITTER - Generating sentence embeddings...\n"
     ]
    }
   ],
   "source": [
    "glove_embeddings = glove.generate_embeddings(word_embeddings_df[model_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of size (100, 200)\n",
      "# Examples: 100\n",
      "Embeddings size: 200\n"
     ]
    }
   ],
   "source": [
    "print(f'Vector of size ({len(glove_embeddings)}, {len(glove_embeddings[0])})')\n",
    "print(f'# Examples: {len(distil_embeddings)}')\n",
    "print(f'Embeddings size: {len(glove_embeddings[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.19305408, -0.09725341,  0.02407458,  0.02520164, -0.01836262,\n",
       "        0.06644535,  0.56134343, -0.09498324, -0.14953393, -0.17344882,\n",
       "       -0.06203576, -0.01623033, -0.5874654 , -0.03406139,  0.01704982,\n",
       "        0.23174308, -0.054517  ,  0.11802665,  0.01858332, -0.14692163,\n",
       "       -0.13663086,  0.13083495, -0.07296988, -0.07434546, -0.12882087],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_embeddings[0][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:08:36,290 - INFO     | models.embeddings | Initializing W2V-GOOGLE for Word Embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:18:39,512 - INFO     | gensim.downloader | word2vec-google-news-300 downloaded\n",
      "2023-04-18 16:18:39,515 - INFO     | gensim.models.keyedvectors | loading projection weights from /Users/lorenzo/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz\n",
      "2023-04-18 16:19:03,607 - INFO     | gensim.utils | KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from /Users/lorenzo/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz', 'binary': True, 'encoding': 'utf8', 'datetime': '2023-04-18T16:19:03.607136', 'gensim': '4.3.1', 'python': '3.9.13 (main, Mar  3 2023, 13:16:29) \\n[Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-13.3.1-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "word2vec = WordEmbeddings(name='w2v-google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:19:03,631 - INFO     | models.embeddings | W2V-GOOGLE - Generating sentence embeddings...\n"
     ]
    }
   ],
   "source": [
    "word2vec_embeddings = word2vec.generate_embeddings(word_embeddings_df[model_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of size (100, 300)\n",
      "# Examples: 100\n",
      "Embeddings size: 300\n"
     ]
    }
   ],
   "source": [
    "print(f'Vector of size ({len(word2vec_embeddings)}, {len(word2vec_embeddings[0])})')\n",
    "print(f'# Examples: {len(word2vec_embeddings)}')\n",
    "print(f'Embeddings size: {len(word2vec_embeddings[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0322404 ,  0.03132523, -0.02603504,  0.05654375, -0.09165423,\n",
       "        0.0203185 ,  0.1093035 , -0.11701238,  0.10635021,  0.04933522,\n",
       "       -0.08406031, -0.07944631, -0.00459405,  0.03160654, -0.10748859,\n",
       "        0.08056179, -0.01320772,  0.0772627 , -0.06542898, -0.08310859,\n",
       "       -0.00585938, -0.01770516,  0.02913577,  0.04466567, -0.00073136],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_embeddings[0][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:19:03,741 - INFO     | models.embeddings | Initializing GLOVE-WIKI for Word Embeddings\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 376.1/376.1MB downloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:21:16,410 - INFO     | gensim.downloader | glove-wiki-gigaword-300 downloaded\n",
      "2023-04-18 16:21:16,413 - INFO     | gensim.models.keyedvectors | loading projection weights from /Users/lorenzo/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz\n",
      "2023-04-18 16:21:50,583 - INFO     | gensim.utils | KeyedVectors lifecycle event {'msg': 'loaded (400000, 300) matrix of type float32 from /Users/lorenzo/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz', 'binary': False, 'encoding': 'utf8', 'datetime': '2023-04-18T16:21:50.583536', 'gensim': '4.3.1', 'python': '3.9.13 (main, Mar  3 2023, 13:16:29) \\n[Clang 14.0.0 (clang-1400.0.29.202)]', 'platform': 'macOS-13.3.1-arm64-arm-64bit', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "wiki = WordEmbeddings(name='glove-wiki')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-18 16:21:50,601 - INFO     | models.embeddings | GLOVE-WIKI - Generating sentence embeddings...\n"
     ]
    }
   ],
   "source": [
    "wiki_embeddings = wiki.generate_embeddings(word_embeddings_df[model_col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of size (100, 300)\n",
      "# Examples: 100\n",
      "Embeddings size: 300\n"
     ]
    }
   ],
   "source": [
    "print(f'Vector of size ({len(wiki_embeddings)}, {len(wiki_embeddings[0])})')\n",
    "print(f'# Examples: {len(wiki_embeddings)}')\n",
    "print(f'Embeddings size: {len(wiki_embeddings[0])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.12441022,  0.11495119, -0.02298809, -0.14069755,  0.05530136,\n",
       "       -0.08360783, -0.08374323,  0.06676266,  0.01220673, -1.1837194 ,\n",
       "        0.05716083,  0.06649845, -0.17764433,  0.03277824,  0.03594254,\n",
       "       -0.01795638, -0.0316156 , -0.08364933, -0.06366695,  0.05146493,\n",
       "       -0.07871727,  0.13870214,  0.10245264,  0.0136757 , -0.31698236],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_embeddings[0][:25]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
