{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eddb2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 19:03:09,218 - INFO     | config     | Loading environment variables\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from models.generation import Model\n",
    "\n",
    "from config import HUGGINGFACE_TOKEN, GPT4ALL_PATH, LLAMA_7B_PATH, LLAMA_13B_PATH\n",
    "\n",
    "from helpers.data_helpers import save_to_parquet\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db74f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cooldown in seconds every 50 iterations and fast cooldown every iteration\n",
    "COOLDOWN = 120\n",
    "FAST_COOLDOWN = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ba148d",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c602859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 19:03:10,167 - INFO     | __main__   | 21711 tweets in generation set.\n"
     ]
    }
   ],
   "source": [
    "tweets = pd.read_parquet('data/eval_tweets_202342.parquet')\n",
    "logger.info(f'{len(tweets)} tweets in generation set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a94b9728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 19:03:10,352 - INFO     | __main__   | Generating from 100 tweets.\n"
     ]
    }
   ],
   "source": [
    "N_TWEETS = 100\n",
    "logger.info(f'Generating from {N_TWEETS} tweets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e693707",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tweets = tweets.iloc[:N_TWEETS].copy()\n",
    "output_tweets.drop(columns=['created_at', 'entities'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b914c34f",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9670a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"Answer the question based on the context below. \\\n",
    "    Context: You are a marketing and customer relationship management assistant, \\\n",
    "    your task is to classify a given tweet as either a \\\n",
    "    potential lead or not. Provide your detailed analysis of the following tweet \\\n",
    "    as a potential lead in the context of marketing and customer relationship management. \\\n",
    "    Tweet: {tweet} \\\n",
    "    Question: Is the above tweet a potential lead? Yes or No? Why?. \\\n",
    "    Answer: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4452046",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a9d46",
   "metadata": {},
   "source": [
    "### BLOOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6719cc81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 19:03:12,567 - INFO     | models.generation | \n",
      "Initializing BLOOM model  - Temp: 1e-10 - Context window: 2048 - Max tokens: 256\n"
     ]
    }
   ],
   "source": [
    "bloom = Model(\n",
    "    model_name='bloom',\n",
    "    hf_api=HUGGINGFACE_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7343505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 19:03:13,511 - INFO     | models.generation | Injecting Variables: ['tweet']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer the question based on the context below.     Context: You are a marketing and customer relationship management assistant,     your task is to classify a given tweet as either a     potential lead or not. Provide your detailed analysis of the following tweet     as a potential lead in the context of marketing and customer relationship management.     Tweet: {tweet}     Question: Is the above tweet a potential lead? Yes or No? Why?.     Answer: '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloom.init_prompt(template=PROMPT_TEMPLATE, input_vars=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "274780c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 19:14:27,977 - INFO     | __main__   | Starting BLOOM generation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "027edf6a73ae4e5cbedb6e92a63161d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 19:16:33,421 - INFO     | __main__   | 50 - Saving checkpoint...\n"
     ]
    },
    {
     "ename": "ArrowTypeError",
     "evalue": "(\"Expected bytes, got a 'int' object\", 'Conversion failed for column bloom_out with type object')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m - Saving checkpoint...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m output_tweets[\u001b[39m'\u001b[39m\u001b[39mbloom_out\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m bloom_outs\n\u001b[0;32m---> 10\u001b[0m save_to_parquet(data_dir\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39moutputs\u001b[39;49m\u001b[39m'\u001b[39;49m, df\u001b[39m=\u001b[39;49moutput_tweets, name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39moutput_tweets\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/repos/msc-thesis-llm-clustering/helpers/data_helpers.py:41\u001b[0m, in \u001b[0;36msave_to_parquet\u001b[0;34m(data_dir, df, name)\u001b[0m\n\u001b[1;32m     37\u001b[0m year \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(datetime\u001b[39m.\u001b[39mnow()\u001b[39m.\u001b[39myear)\n\u001b[1;32m     39\u001b[0m date_str \u001b[39m=\u001b[39m year \u001b[39m+\u001b[39m month \u001b[39m+\u001b[39m day\n\u001b[0;32m---> 41\u001b[0m df\u001b[39m.\u001b[39;49mto_parquet(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mdata_dir\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mname\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mdate_str\u001b[39m}\u001b[39;49;00m\u001b[39m.parquet\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     42\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m.parquet saved.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/pandas/core/frame.py:2976\u001b[0m, in \u001b[0;36mDataFrame.to_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2889\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2890\u001b[0m \u001b[39mWrite a DataFrame to the binary parquet format.\u001b[39;00m\n\u001b[1;32m   2891\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2972\u001b[0m \u001b[39m>>> content = f.read()\u001b[39;00m\n\u001b[1;32m   2973\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2974\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparquet\u001b[39;00m \u001b[39mimport\u001b[39;00m to_parquet\n\u001b[0;32m-> 2976\u001b[0m \u001b[39mreturn\u001b[39;00m to_parquet(\n\u001b[1;32m   2977\u001b[0m     \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2978\u001b[0m     path,\n\u001b[1;32m   2979\u001b[0m     engine,\n\u001b[1;32m   2980\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   2981\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   2982\u001b[0m     partition_cols\u001b[39m=\u001b[39;49mpartition_cols,\n\u001b[1;32m   2983\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   2984\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   2985\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/pandas/io/parquet.py:430\u001b[0m, in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    426\u001b[0m impl \u001b[39m=\u001b[39m get_engine(engine)\n\u001b[1;32m    428\u001b[0m path_or_buf: FilePath \u001b[39m|\u001b[39m WriteBuffer[\u001b[39mbytes\u001b[39m] \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO() \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m path\n\u001b[0;32m--> 430\u001b[0m impl\u001b[39m.\u001b[39;49mwrite(\n\u001b[1;32m    431\u001b[0m     df,\n\u001b[1;32m    432\u001b[0m     path_or_buf,\n\u001b[1;32m    433\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    434\u001b[0m     index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m    435\u001b[0m     partition_cols\u001b[39m=\u001b[39;49mpartition_cols,\n\u001b[1;32m    436\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    437\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    438\u001b[0m )\n\u001b[1;32m    440\u001b[0m \u001b[39mif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    441\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, io\u001b[39m.\u001b[39mBytesIO)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/pandas/io/parquet.py:174\u001b[0m, in \u001b[0;36mPyArrowImpl.write\u001b[0;34m(self, df, path, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     from_pandas_kwargs[\u001b[39m\"\u001b[39m\u001b[39mpreserve_index\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m index\n\u001b[0;32m--> 174\u001b[0m table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapi\u001b[39m.\u001b[39;49mTable\u001b[39m.\u001b[39;49mfrom_pandas(df, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfrom_pandas_kwargs)\n\u001b[1;32m    176\u001b[0m path_or_handle, handles, kwargs[\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m _get_path_or_handle(\n\u001b[1;32m    177\u001b[0m     path,\n\u001b[1;32m    178\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mfilesystem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m     is_dir\u001b[39m=\u001b[39mpartition_cols \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    182\u001b[0m )\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    184\u001b[0m     \u001b[39misinstance\u001b[39m(path_or_handle, io\u001b[39m.\u001b[39mBufferedWriter)\n\u001b[1;32m    185\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(path_or_handle, \u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    186\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_handle\u001b[39m.\u001b[39mname, (\u001b[39mstr\u001b[39m, \u001b[39mbytes\u001b[39m))\n\u001b[1;32m    187\u001b[0m ):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/pyarrow/table.pxi:3557\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/pyarrow/pandas_compat.py:611\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m(df, schema, preserve_index, nthreads, columns, safe)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39misinstance\u001b[39m(arr, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    607\u001b[0m             arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mcontiguous \u001b[39mand\u001b[39;00m\n\u001b[1;32m    608\u001b[0m             \u001b[39missubclass\u001b[39m(arr\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, np\u001b[39m.\u001b[39minteger))\n\u001b[1;32m    610\u001b[0m \u001b[39mif\u001b[39;00m nthreads \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 611\u001b[0m     arrays \u001b[39m=\u001b[39m [convert_column(c, f)\n\u001b[1;32m    612\u001b[0m               \u001b[39mfor\u001b[39;00m c, f \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(columns_to_convert, convert_fields)]\n\u001b[1;32m    613\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     arrays \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/pyarrow/pandas_compat.py:611\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39misinstance\u001b[39m(arr, np\u001b[39m.\u001b[39mndarray) \u001b[39mand\u001b[39;00m\n\u001b[1;32m    607\u001b[0m             arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mcontiguous \u001b[39mand\u001b[39;00m\n\u001b[1;32m    608\u001b[0m             \u001b[39missubclass\u001b[39m(arr\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, np\u001b[39m.\u001b[39minteger))\n\u001b[1;32m    610\u001b[0m \u001b[39mif\u001b[39;00m nthreads \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 611\u001b[0m     arrays \u001b[39m=\u001b[39m [convert_column(c, f)\n\u001b[1;32m    612\u001b[0m               \u001b[39mfor\u001b[39;00m c, f \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(columns_to_convert, convert_fields)]\n\u001b[1;32m    613\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     arrays \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[39mexcept\u001b[39;00m (pa\u001b[39m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[39m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[39m.\u001b[39mArrowTypeError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[39m.\u001b[39margs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mConversion failed for column \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m with type \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[39m.\u001b[39mformat(col\u001b[39m.\u001b[39mname, col\u001b[39m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m field_nullable \u001b[39mand\u001b[39;00m result\u001b[39m.\u001b[39mnull_count \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    600\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mField \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m was non-nullable but pandas column \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    601\u001b[0m                      \u001b[39m\"\u001b[39m\u001b[39mhad \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m null values\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mstr\u001b[39m(field),\n\u001b[1;32m    602\u001b[0m                                                  result\u001b[39m.\u001b[39mnull_count))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mdataframe_to_arrays.<locals>.convert_column\u001b[0;34m(col, field)\u001b[0m\n\u001b[1;32m    589\u001b[0m     type_ \u001b[39m=\u001b[39m field\u001b[39m.\u001b[39mtype\n\u001b[1;32m    591\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49marray(col, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49mtype_, from_pandas\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, safe\u001b[39m=\u001b[39;49msafe)\n\u001b[1;32m    593\u001b[0m \u001b[39mexcept\u001b[39;00m (pa\u001b[39m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[39m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[39m.\u001b[39mArrowTypeError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    596\u001b[0m     e\u001b[39m.\u001b[39margs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mConversion failed for column \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m with type \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[39m.\u001b[39mformat(col\u001b[39m.\u001b[39mname, col\u001b[39m.\u001b[39mdtype),)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/pyarrow/array.pxi:316\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/pyarrow/array.pxi:83\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.13/envs/thesis/lib/python3.9/site-packages/pyarrow/error.pxi:123\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: (\"Expected bytes, got a 'int' object\", 'Conversion failed for column bloom_out with type object')"
     ]
    }
   ],
   "source": [
    "logger.info('Starting BLOOM generation...')\n",
    "bloom_outs = [' ' for _ in range(N_TWEETS)]\n",
    "for i, tweet in enumerate(tqdm(output_tweets['full_text'])):\n",
    "    bloom_llm, bloom_out = bloom.generate(inject_obj=tweet)\n",
    "    bloom_outs[i] = bloom_out\n",
    "    time.sleep(FAST_COOLDOWN)\n",
    "    if (i+1) % 50 == 0:\n",
    "        logger.info(f'{i+1} - Saving checkpoint...')\n",
    "        output_tweets['bloom_out'] = np.array(bloom_outs)\n",
    "        save_to_parquet(data_dir='outputs', df=output_tweets, name='output_tweets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57cad90",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tweets['bloom_out'] = bloom_outs\n",
    "save_to_parquet(data_dir='outputs', df=output_tweets, name='output_tweets')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeca1e6",
   "metadata": {},
   "source": [
    "### GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "296565e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 17:25:10,396 - INFO     | models.generation | \n",
      "Initializing GPT4ALL model  - Temp: 1e-10 - Context window: 2048 - Max tokens: 256\n",
      "llama_model_load: loading model from '/Users/lorenzo/Documents/repos/msc-thesis-llm-clustering/.models/gpt4all-7B/gpt4all-converted.bin' - please wait ...\n",
      "llama_model_load: n_vocab = 32001\n",
      "llama_model_load: n_ctx   = 2048\n",
      "llama_model_load: n_embd  = 4096\n",
      "llama_model_load: n_mult  = 256\n",
      "llama_model_load: n_head  = 32\n",
      "llama_model_load: n_layer = 32\n",
      "llama_model_load: n_rot   = 128\n",
      "llama_model_load: f16     = 2\n",
      "llama_model_load: n_ff    = 11008\n",
      "llama_model_load: n_parts = 1\n",
      "llama_model_load: type    = 1\n",
      "llama_model_load: ggml map size = 4017.70 MB\n",
      "llama_model_load: ggml ctx size =  81.25 KB\n",
      "llama_model_load: mem required  = 5809.78 MB (+ 2052.00 MB per state)\n",
      "llama_model_load: loading tensors from '/Users/lorenzo/Documents/repos/msc-thesis-llm-clustering/.models/gpt4all-7B/gpt4all-converted.bin'\n",
      "llama_model_load: model size =  4017.27 MB / num tensors = 291\n",
      "llama_init_from_file: kv self size  = 2048.00 MB\n"
     ]
    }
   ],
   "source": [
    "gpt4all = Model(\n",
    "    model_name='gpt4all',\n",
    "    n_threads=6,\n",
    "    local_model_path=GPT4ALL_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba7a2a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 17:25:10,958 - INFO     | models.generation | Injecting Variables: ['tweet']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer the question based on the context below.     Context: You are a marketing and customer relationship management assistant,     your task is to classify a given tweet as either a     potential lead or not. Provide your analysis of the following social media post (tweet)     as a potential lead in the context of marketing and customer relationship management.     Tweet: {tweet}     Question: Is the above tweet a potential lead? Yes or No? Why?.     Answer: '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4all.init_prompt(template=PROMPT_TEMPLATE, input_vars=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15780b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 17:25:10,981 - INFO     | __main__   | Starting GPT4All generation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e32ff54f8740ceb25708704c5a1156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logger.info('Starting GPT4All generation...')\n",
    "gpt4all_outs = np.zeros(N_TWEETS, dtype=object)\n",
    "for i, tweet in enumerate(tqdm(output_tweets['full_text'])):\n",
    "    gpt4all_llm, gpt4all_out = gpt4all.generate(tweet)\n",
    "    gpt4all_outs.append(gpt4all_out)\n",
    "    time.sleep(FAST_COOLDOWN)\n",
    "    if (i+1) % 50 == 0:\n",
    "        # save checkpoint and cooldown\n",
    "        output_tweets['gpt4all_out'] = gpt4all_outs\n",
    "        save_to_parquet(data_dir='outputs', df=output_tweets, name='output_tweets')\n",
    "        time.sleep(COOLDOWN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1edf1bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tweets['gpt4all_out'] = np.array(gpt4all_outs)\n",
    "save_to_parquet(data_dir='outputs', df=output_tweets, name='output_tweets')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f821cc5c",
   "metadata": {},
   "source": [
    "### Llama 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f1e246",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_7b = Model(\n",
    "    model_name='llama',\n",
    "    n_threads=6,\n",
    "    local_model_path=LLAMA_7B_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14c7b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_7b.init_prompt(template=PROMPT_TEMPLATE, input_vars=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Starting Llama 7B generation...')\n",
    "llama_7b_outs = []\n",
    "output_tweets['llama_7b_out'] = ''\n",
    "for i, tweet in enumerate(tqdm(output_tweets['full_text'])):\n",
    "    llama_7b_llm, llama_7b_out = llama_7b.generate(tweet)\n",
    "    llama_7b_outs.append(llama_7b_out)\n",
    "    time.sleep(FAST_COOLDOWN)\n",
    "    if i % 50:\n",
    "        # save checkpoint and cooldown\n",
    "        output_tweets['llama_7b_out'] = np.array(llama_7b_outs)\n",
    "        save_to_parquet(data_dir='outputs', df=output_tweets, name='output_tweets')\n",
    "        time.sleep(COOLDOWN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b7ed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tweets['llama_7b_out'] = np.array(llama_7b_outs)\n",
    "save_to_parquet(data_dir='outputs', df=output_tweets, name='output_tweets')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3f78f28",
   "metadata": {},
   "source": [
    "### Llama 13B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49590f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_13b = Model(\n",
    "    model_name='llama',\n",
    "    n_threads=6,\n",
    "    local_model_path=LLAMA_13B_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67639272",
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_13b.init_prompt(template=PROMPT_TEMPLATE, input_vars=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb549e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Starting Llama 13B generation...')\n",
    "llama_13b_outs = []\n",
    "output_tweets['llama_13b_out'] = ''\n",
    "for i, tweet in enumerate(tqdm(output_tweets['full_text'])):\n",
    "    llama_13b_llm, llama_13b_out = llama_13b.generate(tweet)\n",
    "    llama_13b_outs.append(llama_13b_out)\n",
    "    time.sleep(FAST_COOLDOWN)\n",
    "    if i % 50:\n",
    "        # save checkpoint and cooldown\n",
    "        output_tweets['llama_13b_out'] = np.array(llama_13b_outs)\n",
    "        save_to_parquet(data_dir='outputs', df=output_tweets, name='output_tweets')\n",
    "        time.sleep(COOLDOWN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f278d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tweets['llama_13b_out'] = np.array(llama_13b_outs)\n",
    "save_to_parquet(data_dir='outputs', df=output_tweets, name='output_tweets')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
