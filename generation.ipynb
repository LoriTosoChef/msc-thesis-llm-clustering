{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eddb2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 09:59:04,385 - INFO     | config     | Loading environment variables\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from models.generation import Model\n",
    "\n",
    "from config import HUGGINGFACE_TOKEN, GPT4ALL_PATH, LLAMA_7B_PATH, LLAMA_13B_PATH\n",
    "\n",
    "from helpers.data_helpers import save_to_parquet\n",
    "from helpers.generation_helpers import generation_loop\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0db74f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cooldown in seconds every 50 iterations and fast cooldown every iteration\n",
    "SLOW_COOLDOWN = 120\n",
    "FAST_COOLDOWN = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ba148d",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c602859",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 23:11:17,747 - INFO     | __main__   | 21711 tweets in generation set.\n"
     ]
    }
   ],
   "source": [
    "tweets = pd.read_parquet('data/eval_tweets_202342.parquet')\n",
    "logger.info(f'{len(tweets)} tweets in generation set.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a94b9728",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 23:11:18,222 - INFO     | __main__   | Generating from 100 tweets.\n"
     ]
    }
   ],
   "source": [
    "N_TWEETS = 100\n",
    "logger.info(f'Generating from {N_TWEETS} tweets.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6e693707",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_tweets = tweets.iloc[:N_TWEETS].copy()\n",
    "output_tweets.drop(columns=['created_at', 'entities'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b914c34f",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9670a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_TEMPLATE = \"\"\"Answer the question based on the context below. \\\n",
    "    Context: You are a marketing and customer relationship management assistant, \\\n",
    "    your task is to classify a given tweet as either a \\\n",
    "    potential lead or not. Provide your detailed analysis of the following tweet \\\n",
    "    as a potential lead in the context of marketing and customer relationship management. \\\n",
    "    Tweet: {tweet} \\\n",
    "    Question: Is the above tweet a potential lead? Yes or No? Why?. \\\n",
    "    Answer: \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4452046",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a9d46",
   "metadata": {},
   "source": [
    "### BLOOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6719cc81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 23:11:20,687 - INFO     | models.generation | \n",
      "Initializing BLOOM model  - Temp: 1e-10 - Context window: 2048 - Max tokens: 256\n"
     ]
    }
   ],
   "source": [
    "bloom = Model(\n",
    "    model_name='bloom',\n",
    "    hf_api=HUGGINGFACE_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7343505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 23:11:21,405 - INFO     | models.generation | Injecting Variables: ['tweet']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer the question based on the context below.     Context: You are a marketing and customer relationship management assistant,     your task is to classify a given tweet as either a     potential lead or not. Provide your detailed analysis of the following tweet     as a potential lead in the context of marketing and customer relationship management.     Tweet: {tweet}     Question: Is the above tweet a potential lead? Yes or No? Why?.     Answer: '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bloom.init_prompt(template=PROMPT_TEMPLATE, input_vars=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "274780c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 23:11:22,066 - INFO     | helpers.generation_helpers | Starting BLOOM generation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f264546b114c298b09a3d3c7ec55b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 23:15:58,932 - INFO     | helpers.generation_helpers | Step: 50 - Saving checkpoint and cooldown for 2.0m...\n",
      "2023-04-04 23:15:58,945 - INFO     | helpers.data_helpers | 200T_bloom_alpaca3b_alpaca_11b.parquet saved.\n",
      "2023-04-04 23:20:42,093 - INFO     | helpers.generation_helpers | Step: 100 - Saving checkpoint and cooldown for 2.0m...\n",
      "2023-04-04 23:20:42,115 - INFO     | helpers.data_helpers | 200T_bloom_alpaca3b_alpaca_11b.parquet saved.\n",
      "2023-04-04 23:20:42,123 - INFO     | helpers.data_helpers | 200T_bloom_alpaca3b_alpaca_11b.parquet saved.\n"
     ]
    }
   ],
   "source": [
    "output_tweets = generation_loop(\n",
    "    model=bloom,\n",
    "    model_col='bloom',\n",
    "    n=N_TWEETS,\n",
    "    tweets=output_tweets,\n",
    "    fast_cool=FAST_COOLDOWN,\n",
    "    slow_cool=SLOW_COOLDOWN  ,\n",
    "    out_dir='outputs',\n",
    "    out_name='200T_bloom_alpaca3b_alpaca_11b'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd7b488",
   "metadata": {},
   "source": [
    "### Alpaca Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff6646a",
   "metadata": {},
   "source": [
    "#### Alpaca 770M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2561271e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 10:06:37,274 - INFO     | models.generation | \n",
      "Initializing ALPACA-770M model  - Temp: 1e-10 - Context window: 2048 - Max tokens: 256\n"
     ]
    }
   ],
   "source": [
    "alpaca_770m = Model(\n",
    "    model_name='alpaca-770m',\n",
    "    hf_repo='declare-lab/flan-alpaca-large',\n",
    "    hf_api=HUGGINGFACE_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d95a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 10:06:37,934 - INFO     | models.generation | Injecting Variables: ['tweet']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer the question based on the context below.     Context: You are a marketing and customer relationship management assistant,     your task is to classify a given tweet as either a     potential lead or not. Provide your detailed analysis of the following tweet     as a potential lead in the context of marketing and customer relationship management.     Tweet: {tweet}     Question: Is the above tweet a potential lead? Yes or No? Why?.     Answer: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alpaca_770m.init_prompt(template=PROMPT_TEMPLATE, input_vars=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f213d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 10:06:37,993 - INFO     | helpers.generation_helpers | Starting ALPACA-770M generation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ceb48d8ed8434d8c45ead8ebb2ff68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 10:21:11,091 - INFO     | helpers.generation_helpers | Step: 50 - Saving checkpoint and cooldown for 2.0m...\n",
      "2023-04-05 10:21:11,106 - INFO     | helpers.data_helpers | 200T_bloom_alpaca3b_alpaca_11b.parquet saved.\n",
      "2023-04-05 10:35:31,468 - INFO     | helpers.generation_helpers | Step: 100 - Saving checkpoint and cooldown for 2.0m...\n",
      "2023-04-05 10:35:31,491 - INFO     | helpers.data_helpers | 200T_bloom_alpaca3b_alpaca_11b.parquet saved.\n"
     ]
    }
   ],
   "source": [
    "output_tweets = generation_loop(\n",
    "    model=alpaca_770m,\n",
    "    model_col='alpaca_770m',\n",
    "    n=N_TWEETS,\n",
    "    tweets=output_tweets,\n",
    "    fast_cool=FAST_COOLDOWN,\n",
    "    slow_cool=SLOW_COOLDOWN,\n",
    "    out_dir='outputs',\n",
    "    out_name='200T_bloom_alpaca3b_alpaca_11b'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a73ba04",
   "metadata": {},
   "source": [
    "#### Alpaca 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7757834e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 23:20:42,221 - INFO     | models.generation | \n",
      "Initializing ALPACA-3B model  - Temp: 1e-10 - Context window: 2048 - Max tokens: 256\n"
     ]
    }
   ],
   "source": [
    "alpaca_3b = Model(\n",
    "    model_name='alpaca-3b',\n",
    "    hf_repo='declare-lab/flan-alpaca-xl',\n",
    "    hf_api=HUGGINGFACE_TOKEN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e454fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 23:20:42,938 - INFO     | models.generation | Injecting Variables: ['tweet']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer the question based on the context below.     Context: You are a marketing and customer relationship management assistant,     your task is to classify a given tweet as either a     potential lead or not. Provide your detailed analysis of the following tweet     as a potential lead in the context of marketing and customer relationship management.     Tweet: {tweet}     Question: Is the above tweet a potential lead? Yes or No? Why?.     Answer: '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpaca_3b.init_prompt(template=PROMPT_TEMPLATE, input_vars=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "942d9123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 23:20:42,972 - INFO     | helpers.generation_helpers | Starting ALPACA-3B generation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971f5f1cb9b347cd88e703d50f28da3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 23:53:32,946 - INFO     | helpers.generation_helpers | Step: 50 - Saving checkpoint and cooldown for 2.0m...\n",
      "2023-04-04 23:53:32,963 - INFO     | helpers.data_helpers | 200T_bloom_alpaca3b_alpaca_11b.parquet saved.\n",
      "2023-04-05 00:32:41,856 - INFO     | helpers.generation_helpers | Step: 100 - Saving checkpoint and cooldown for 2.0m...\n",
      "2023-04-05 00:32:41,876 - INFO     | helpers.data_helpers | 200T_bloom_alpaca3b_alpaca_11b.parquet saved.\n",
      "2023-04-05 00:32:41,882 - INFO     | helpers.data_helpers | 200T_bloom_alpaca3b_alpaca_11b.parquet saved.\n"
     ]
    }
   ],
   "source": [
    "output_tweets = generation_loop(\n",
    "    model=alpaca_3b,\n",
    "    model_col='alpaca_3b',\n",
    "    n=N_TWEETS,\n",
    "    tweets=output_tweets,\n",
    "    fast_cool=FAST_COOLDOWN,\n",
    "    slow_cool=SLOW_COOLDOWN,\n",
    "    out_dir='outputs',\n",
    "    out_name='200T_bloom_alpaca3b_alpaca_11b'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeca1e6",
   "metadata": {},
   "source": [
    "### GPT4All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "296565e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 19:26:22,097 - INFO     | models.generation | \n",
      "Initializing GPT4ALL model  - Temp: 1e-10 - Context window: 2048 - Max tokens: 256\n",
      "llama_model_load: loading model from '.models/gpt4all-7B/gpt4all-converted.bin' - please wait ...\n",
      "llama_model_load: n_vocab = 32001\n",
      "llama_model_load: n_ctx   = 2048\n",
      "llama_model_load: n_embd  = 4096\n",
      "llama_model_load: n_mult  = 256\n",
      "llama_model_load: n_head  = 32\n",
      "llama_model_load: n_layer = 32\n",
      "llama_model_load: n_rot   = 128\n",
      "llama_model_load: f16     = 2\n",
      "llama_model_load: n_ff    = 11008\n",
      "llama_model_load: n_parts = 1\n",
      "llama_model_load: type    = 1\n",
      "llama_model_load: ggml map size = 4017.70 MB\n",
      "llama_model_load: ggml ctx size =  81.25 KB\n",
      "llama_model_load: mem required  = 5809.78 MB (+ 2052.00 MB per state)\n",
      "llama_model_load: loading tensors from '.models/gpt4all-7B/gpt4all-converted.bin'\n",
      "llama_model_load: model size =  4017.27 MB / num tensors = 291\n",
      "llama_init_from_file: kv self size  = 2048.00 MB\n"
     ]
    }
   ],
   "source": [
    "gpt4all = Model(\n",
    "    model_name='gpt4all',\n",
    "    n_threads=6,\n",
    "    local_model_path=GPT4ALL_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba7a2a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 19:26:26,005 - INFO     | models.generation | Injecting Variables: ['tweet']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer the question based on the context below.     Context: You are a marketing and customer relationship management assistant,     your task is to classify a given tweet as either a     potential lead or not. Provide your detailed analysis of the following tweet     as a potential lead in the context of marketing and customer relationship management.     Tweet: {tweet}     Question: Is the above tweet a potential lead? Yes or No? Why?.     Answer: '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt4all.init_prompt(template=PROMPT_TEMPLATE, input_vars=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15780b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 19:27:00,097 - INFO     | __main__   | Starting GPT4All generation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "855e382cf21044bab991a436e25f9443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 19:41:47,947 - INFO     | helpers.data_helpers | output_tweets.parquet saved.\n",
      "2023-04-04 19:57:23,399 - INFO     | helpers.data_helpers | output_tweets.parquet saved.\n"
     ]
    }
   ],
   "source": [
    "output_tweets = generation_loop(\n",
    "    model=gpt4all,\n",
    "    model_col='gpt4all',\n",
    "    n=N_TWEETS,\n",
    "    tweets=output_tweets,\n",
    "    fast_cool=FAST_COOLDOWN,\n",
    "    slow_cool=SLOW_COOLDOWN,\n",
    "    out_dir='outputs',\n",
    "    out_name='200T_bloom_alpaca3b_alpaca_11b'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f821cc5c",
   "metadata": {},
   "source": [
    "### Llama 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39f1e246",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 20:15:28,928 - INFO     | models.generation | \n",
      "Initializing LLAMA model  - Temp: 1e-10 - Context window: 2048 - Max tokens: 256\n",
      "llama_model_load: loading model from '.models/llama-7B/ggml-model-q4_0.bin' - please wait ...\n",
      "llama_model_load: n_vocab = 32000\n",
      "llama_model_load: n_ctx   = 2048\n",
      "llama_model_load: n_embd  = 4096\n",
      "llama_model_load: n_mult  = 256\n",
      "llama_model_load: n_head  = 32\n",
      "llama_model_load: n_layer = 32\n",
      "llama_model_load: n_rot   = 128\n",
      "llama_model_load: f16     = 2\n",
      "llama_model_load: n_ff    = 11008\n",
      "llama_model_load: n_parts = 1\n",
      "llama_model_load: type    = 1\n",
      "llama_model_load: ggml map size = 4017.70 MB\n",
      "llama_model_load: ggml ctx size =  81.25 KB\n",
      "llama_model_load: mem required  = 5809.78 MB (+ 2052.00 MB per state)\n",
      "llama_model_load: loading tensors from '.models/llama-7B/ggml-model-q4_0.bin'\n",
      "llama_model_load: model size =  4017.27 MB / num tensors = 291\n",
      "llama_init_from_file: kv self size  = 2048.00 MB\n"
     ]
    }
   ],
   "source": [
    "llama_7b = Model(\n",
    "    model_name='llama',\n",
    "    n_threads=6,\n",
    "    local_model_path=LLAMA_7B_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f14c7b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 20:15:33,957 - INFO     | models.generation | Injecting Variables: ['tweet']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer the question based on the context below.     Context: You are a marketing and customer relationship management assistant,     your task is to classify a given tweet as either a     potential lead or not. Provide your detailed analysis of the following tweet     as a potential lead in the context of marketing and customer relationship management.     Tweet: {tweet}     Question: Is the above tweet a potential lead? Yes or No? Why?.     Answer: '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_7b.init_prompt(template=PROMPT_TEMPLATE, input_vars=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efdc035d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 20:15:42,038 - INFO     | __main__   | Starting Llama 7B generation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d23ab6ed754ae4bf59a1dd67f70566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 20:43:13,640 - INFO     | __main__   | 50 - Saving checkpoint...\n",
      "2023-04-04 20:43:13,653 - INFO     | helpers.data_helpers | output_tweets.parquet saved.\n",
      "2023-04-04 21:12:21,825 - INFO     | __main__   | 100 - Saving checkpoint...\n",
      "2023-04-04 21:12:21,832 - INFO     | helpers.data_helpers | output_tweets.parquet saved.\n"
     ]
    }
   ],
   "source": [
    "output_tweets = generation_loop(\n",
    "    model=llama_7b,\n",
    "    model_col='llama_7b',\n",
    "    n=N_TWEETS,\n",
    "    tweets=output_tweets,\n",
    "    fast_cool=FAST_COOLDOWN,\n",
    "    slow_cool=SLOW_COOLDOWN,\n",
    "    out_dir='outputs',\n",
    "    out_name='200T_bloom_alpaca3b_alpaca_11b'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e3f78f28",
   "metadata": {},
   "source": [
    "### Llama 13B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49590f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 10:53:09,501 - INFO     | models.generation | \n",
      "Initializing LLAMA_13B model  - Temp: 1e-10 - Context window: 2048 - Max tokens: 256\n",
      "llama_model_load: loading model from '.models/llama-13B/ggml-model-q4_0.bin' - please wait ...\n",
      "llama_model_load: n_vocab = 32000\n",
      "llama_model_load: n_ctx   = 2048\n",
      "llama_model_load: n_embd  = 5120\n",
      "llama_model_load: n_mult  = 256\n",
      "llama_model_load: n_head  = 40\n",
      "llama_model_load: n_layer = 40\n",
      "llama_model_load: n_rot   = 128\n",
      "llama_model_load: f16     = 2\n",
      "llama_model_load: n_ff    = 13824\n",
      "llama_model_load: n_parts = 2\n",
      "llama_model_load: type    = 2\n",
      "llama_model_load: ggml map size = 7759.83 MB\n",
      "llama_model_load: ggml ctx size = 101.25 KB\n",
      "llama_model_load: mem required  = 9807.93 MB (+ 3216.00 MB per state)\n",
      "llama_model_load: loading tensors from '.models/llama-13B/ggml-model-q4_0.bin'\n",
      "llama_model_load: model size =  7759.39 MB / num tensors = 363\n",
      "llama_init_from_file: kv self size  = 3200.00 MB\n"
     ]
    }
   ],
   "source": [
    "llama_13b = Model(\n",
    "    model_name='llama_13b',\n",
    "    n_threads=6,\n",
    "    local_model_path=LLAMA_13B_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67639272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 10:53:11,087 - INFO     | models.generation | Injecting Variables: ['tweet']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Answer the question based on the context below.     Context: You are a marketing and customer relationship management assistant,     your task is to classify a given tweet as either a     potential lead or not. Provide your detailed analysis of the following tweet     as a potential lead in the context of marketing and customer relationship management.     Tweet: {tweet}     Question: Is the above tweet a potential lead? Yes or No? Why?.     Answer: '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_13b.init_prompt(template=PROMPT_TEMPLATE, input_vars=['tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5cb549e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 10:53:24,667 - INFO     | helpers.generation_helpers | Starting LLAMA_13B generation...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89fd0b6becda48118fea1c8f11bc5e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-05 11:39:09,689 - INFO     | helpers.generation_helpers | Step: 50 - Saving checkpoint and cooldown for 2.0m...\n",
      "2023-04-05 11:39:09,705 - INFO     | helpers.data_helpers | 200T_bloom_alpaca3b_alpaca_11b.parquet saved.\n",
      "2023-04-05 12:24:19,503 - INFO     | helpers.generation_helpers | Step: 100 - Saving checkpoint and cooldown for 2.0m...\n",
      "2023-04-05 12:24:19,533 - INFO     | helpers.data_helpers | 200T_bloom_alpaca3b_alpaca_11b.parquet saved.\n"
     ]
    }
   ],
   "source": [
    "output_tweets = generation_loop(\n",
    "    model=llama_13b,\n",
    "    model_col='llama_13b',\n",
    "    n=N_TWEETS,\n",
    "    tweets=output_tweets,\n",
    "    fast_cool=FAST_COOLDOWN,\n",
    "    slow_cool=SLOW_COOLDOWN,\n",
    "    out_dir='outputs',\n",
    "    out_name='200T_bloom_alpaca3b_alpaca_11b'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2818adc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
